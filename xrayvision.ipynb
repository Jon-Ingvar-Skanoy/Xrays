{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchxrayvision in ./env/lib/python3.10/site-packages (1.2.4)\n",
      "Requirement already satisfied: matplotlib in ./env/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: ipywidgets in ./env/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-image in ./env/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: seaborn in ./env/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: requests>=1 in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.32.3)\n",
      "Requirement already satisfied: torch>=1 in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4 in ./env/lib/python3.10/site-packages (from torchxrayvision) (4.67.0)\n",
      "Requirement already satisfied: imageio in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.36.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in ./env/lib/python3.10/site-packages (from torchxrayvision) (11.0.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in ./env/lib/python3.10/site-packages (from torchxrayvision) (0.20.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./env/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./env/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./env/lib/python3.10/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./env/lib/python3.10/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./env/lib/python3.10/site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: networkx>=2.8 in ./env/lib/python3.10/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: stack-data in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: decorator in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: exceptiongroup in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (1.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (11.6.1.9)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.16.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1->torchxrayvision) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch>=1->torchxrayvision) (3.0.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: pure-eval in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchxrayvision matplotlib numpy pandas ipywidgets scikit-learn scikit-image seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TorchXRayVision: A library of chest X-ray datasets and models](https://arxiv.org/pdf/2111.00595)\n",
    "\n",
    "https://github.com/naitik2314/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/projects/Xrays/env/lib/python3.10/site-packages/torchxrayvision/utils.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# PyTorch and data handling\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Image processing\n",
    "import skimage\n",
    "import skimage.transform\n",
    "\n",
    "# Machine learning metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "# TorchXRayVision library\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = max(1, os.cpu_count() - 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_samples = 1000\n",
    "num_epochs = 10\n",
    "unique_patients = True\n",
    "pathology_masks = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_tar_images = \"/mnt/b/Xray/images/\"\n",
    "\n",
    "path_dataset = \"/mnt/b/Xray/\" \n",
    "path_images = \"/mnt/b/Xray/images/images/\"\n",
    "path_csv_list = \"/mnt/b/Xray/Data_Entry_2017.csv\"\n",
    "path_train_val_list = \"/mnt/b/Xray/train_val_list.txt\"\n",
    "path_test_list = \"/mnt/b/Xray/test_list.txt\"\n",
    "\n",
    "os.makedirs(path_dataset, exist_ok=True)\n",
    "\n",
    "path_models = \"/mnt/b/Xray/models/\"\n",
    "checkpoint_dir = \"/mnt/b/Xray/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(self, file_list, image_dir, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.file_list[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if needed\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Extract patient_id (optional)\n",
    "        patient_id = img_name.split(\"_\")[0]\n",
    "\n",
    "        return {\"img\": image, \"filename\": img_name, \"patient_id\": patient_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(link, folder, idx):\n",
    "    \"\"\"Downloads a file from a link to the specified folder.\"\"\"\n",
    "    file_name = f'images_{idx+1:03d}.tar.gz'\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"{file_name} already exists, skipping download.\")\n",
    "        return file_path\n",
    "    try:\n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        urllib.request.urlretrieve(link, file_path)\n",
    "        print(f\"{file_name} downloaded successfully.\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file_path, folder):\n",
    "    \"\"\"Extracts a .tar.gz file to the specified folder.\"\"\"\n",
    "    extracted_flag = file_path.replace('.tar.gz', '_extracted.flag')\n",
    "    if os.path.exists(extracted_flag):\n",
    "        print(f\"{os.path.basename(file_path)} already extracted, skipping.\")\n",
    "        return\n",
    "    try:\n",
    "        print(f\"Extracting {os.path.basename(file_path)}...\")\n",
    "        with tarfile.open(file_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=folder)\n",
    "        with open(extracted_flag, 'w') as f:\n",
    "            f.write('extracted')\n",
    "        print(f\"{os.path.basename(file_path)} extracted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract {os.path.basename(file_path)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_link(idx, link):\n",
    "    \"\"\"Handles downloading and extracting a single link.\"\"\"\n",
    "    file_path = download_file(link, dir_tar_images, idx)\n",
    "    if file_path:\n",
    "        extract_file(file_path, dir_tar_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_lists(train_val_path, test_path):\n",
    "    \"\"\"\n",
    "    Load file lists from the provided paths.\n",
    "    \"\"\"\n",
    "    with open(train_val_path, 'r') as f:\n",
    "        train_val_files = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "    with open(test_path, 'r') as f:\n",
    "        test_files = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return train_val_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_by_file_list(dataset, train_val_files, test_files):\n",
    "    \"\"\"\n",
    "    Split the dataset into train/validation and test sets based on file lists.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The full NIH_Dataset object.\n",
    "        train_val_files: List of filenames for train/validation.\n",
    "        test_files: List of filenames for test.\n",
    "    \n",
    "    Returns:\n",
    "        train_val_dataset, test_dataset: Subsets of the original dataset.\n",
    "    \"\"\"\n",
    "    # Create a mask for matching filenames\n",
    "    train_val_mask = dataset.csv['Image Index'].isin(train_val_files)\n",
    "    test_mask = dataset.csv['Image Index'].isin(test_files)\n",
    "\n",
    "    # Get indices of matched files\n",
    "    train_val_indices = dataset.csv[train_val_mask].index.tolist()\n",
    "    test_indices = dataset.csv[test_mask].index.tolist()\n",
    "\n",
    "    # Create dataset subsets\n",
    "    train_val_dataset = Subset(dataset, train_val_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "    return train_val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    Load the model, optimizer, and scaler states from a checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "        model (torch.nn.Module): The model to load the state into.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "        scaler (torch.cuda.amp.GradScaler): The gradient scaler to load the state into.\n",
    "\n",
    "    Returns:\n",
    "        int: The starting epoch to resume training.\n",
    "        float: The loss at the checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Resuming from epoch {start_epoch}, loss: {loss:.4f}\")\n",
    "    return start_epoch, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_with_masks(samples, dataset, max_samples=4):\n",
    "    \"\"\"\n",
    "    Plot multiple X-ray images side-by-side along with their semantic and pathology masks (if available).\n",
    "    Only plots samples with available masks, up to `max_samples`.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for sample in samples:\n",
    "        if \"pathology_masks\" in sample and sample[\"pathology_masks\"]:\n",
    "            width = len(sample[\"pathology_masks\"])\n",
    "            fig, axs = plt.subplots(1, max(2, 1 + width), sharey=True, figsize=(3 + 3 * width, 3))\n",
    "            axs[0].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "            axs[0].set_title(f\"Index: {sample['idx']}\")\n",
    "            for i, patho in enumerate(sample[\"pathology_masks\"].keys()):\n",
    "                axs[i + 1].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "                axs[i + 1].imshow(sample[\"pathology_masks\"][patho][0] + 1, alpha=0.5)\n",
    "                axs[i + 1].set_title(dataset.pathologies[patho])\n",
    "            plt.show()\n",
    "            count += 1\n",
    "\n",
    "        elif \"semantic_masks\" in sample and sample[\"semantic_masks\"]:\n",
    "            width = len(sample[\"semantic_masks\"])\n",
    "            fig, axs = plt.subplots(1, max(2, 1 + width), sharey=True, figsize=(3 + 3 * width, 3))\n",
    "            axs[0].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "            axs[0].set_title(f\"Index: {sample['idx']}\")\n",
    "            for i, patho in enumerate(sample[\"semantic_masks\"].keys()):\n",
    "                axs[i + 1].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "                axs[i + 1].imshow(sample[\"semantic_masks\"][patho][0] + 1, alpha=0.5)\n",
    "                axs[i + 1].set_title(patho)\n",
    "            plt.show()\n",
    "            count += 1\n",
    "\n",
    "        if count >= max_samples:  # Stop after plotting max_samples\n",
    "            break\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No samples with masks found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_002.tar.gz already exists, skipping download.\n",
      "images_001.tar.gz already exists, skipping download.\n",
      "images_003.tar.gz already exists, skipping download.\n",
      "images_002.tar.gz already extracted, skipping.\n",
      "images_001.tar.gz already extracted, skipping.\n",
      "images_005.tar.gz already exists, skipping download.\n",
      "images_004.tar.gz already exists, skipping download.\n",
      "images_003.tar.gz already extracted, skipping.\n",
      "images_004.tar.gz already extracted, skipping.\n",
      "images_007.tar.gz already exists, skipping download.\n",
      "images_008.tar.gz already exists, skipping download.\n",
      "images_005.tar.gz already extracted, skipping.\n",
      "images_006.tar.gz already exists, skipping download.\n",
      "images_009.tar.gz already exists, skipping download.\n",
      "images_007.tar.gz already extracted, skipping.\n",
      "images_006.tar.gz already extracted, skipping.\n",
      "images_010.tar.gz already exists, skipping download.\n",
      "images_009.tar.gz already extracted, skipping.\n",
      "images_008.tar.gz already extracted, skipping.\n",
      "images_011.tar.gz already exists, skipping download.\n",
      "images_012.tar.gz already exists, skipping download.\n",
      "images_010.tar.gz already extracted, skipping.\n",
      "images_011.tar.gz already extracted, skipping.\n",
      "images_012.tar.gz already extracted, skipping.\n",
      "Download and extraction complete. Please check the extracted files.\n"
     ]
    }
   ],
   "source": [
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(lambda args: process_link(*args), enumerate(links))\n",
    "\n",
    "print(\"Download and extraction complete. Please check the extracted files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    xrv.datasets.XRayCenterCrop(),   # Crop the center of the image\n",
    "    xrv.datasets.XRayResizer(224),  # Resize to 224x224\n",
    "    # transforms.ToTensor(),          # Convert to tensor\n",
    "    # transforms.Lambda(lambda x: x.unsqueeze(0) if x.dim() == 2 else x),  # Add channel dimension if missing\n",
    "    # transforms.Lambda(lambda x: (x / 2048.0) * 1024.0)  # Normalize to [-1024, 1024]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lung Lesion doesn't exist. Adding nans instead.\n",
      "Fracture doesn't exist. Adding nans instead.\n",
      "Lung Opacity doesn't exist. Adding nans instead.\n",
      "Enlarged Cardiomediastinum doesn't exist. Adding nans instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = xrv.datasets.NIH_Dataset(\n",
    "    imgpath=path_images,\n",
    "    csvpath=f\"{path_dataset}/Data_Entry_2017_v2020.csv\",\n",
    "    transform=transforms,\n",
    "    views=[\"PA\", \"AP\"],\n",
    "    unique_patients=unique_patients, # One image per patient\n",
    "    pathology_masks=pathology_masks, # Load pathology masks\n",
    ")\n",
    "xrv.datasets.relabel_dataset(xrv.datasets.default_pathologies, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Atelectasis': {np.float64(0.0): 29140, np.float64(1.0): 1665},\n",
      " 'Cardiomegaly': {np.float64(0.0): 30028, np.float64(1.0): 777},\n",
      " 'Consolidation': {np.float64(0.0): 30369, np.float64(1.0): 436},\n",
      " 'Edema': {np.float64(0.0): 30727, np.float64(1.0): 78},\n",
      " 'Effusion': {np.float64(0.0): 29565, np.float64(1.0): 1240},\n",
      " 'Emphysema': {np.float64(0.0): 30539, np.float64(1.0): 266},\n",
      " 'Enlarged Cardiomediastinum': {},\n",
      " 'Fibrosis': {np.float64(0.0): 30239, np.float64(1.0): 566},\n",
      " 'Fracture': {},\n",
      " 'Hernia': {np.float64(0.0): 30724, np.float64(1.0): 81},\n",
      " 'Infiltration': {np.float64(0.0): 27354, np.float64(1.0): 3451},\n",
      " 'Lung Lesion': {},\n",
      " 'Lung Opacity': {},\n",
      " 'Mass': {np.float64(0.0): 29521, np.float64(1.0): 1284},\n",
      " 'Nodule': {np.float64(0.0): 29135, np.float64(1.0): 1670},\n",
      " 'Pleural_Thickening': {np.float64(0.0): 30051, np.float64(1.0): 754},\n",
      " 'Pneumonia': {np.float64(0.0): 30631, np.float64(1.0): 174},\n",
      " 'Pneumothorax': {np.float64(0.0): 30553, np.float64(1.0): 252}}\n",
      "NIH_Dataset num_samples=30805 views=['PA', 'AP'] data_aug=None\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Dataset: 28008 samples\n",
      "Test Dataset: 2797 samples\n"
     ]
    }
   ],
   "source": [
    "train_val_files, test_files = load_file_lists(path_train_val_list, path_test_list)\n",
    "train_val_dataset, test_dataset = split_dataset_by_file_list(dataset, train_val_files, test_files)\n",
    "\n",
    "print(f\"Train/Val Dataset: {len(train_val_dataset)} samples\")\n",
    "print(f\"Test Dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 800 samples\n",
      "Validation Dataset: 200 samples\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(num_samples))\n",
    "\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Subset(train_val_dataset, train_indices)\n",
    "val_dataset = Subset(train_val_dataset, val_indices)\n",
    "\n",
    "print(f\"Train Dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation Dataset: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     images, labels = batch['img'], batch['lab']\n",
    "#     print(f\"Train batch: {images.shape}, {labels.shape}\")\n",
    "#     break\n",
    "\n",
    "# for batch in val_loader:\n",
    "#     images, labels = batch['img'], batch['lab']\n",
    "#     print(f\"Validation batch: {images.shape}, {labels.shape}\")\n",
    "#     break\n",
    "\n",
    "# for batch in test_loader:\n",
    "#     images, labels = batch['img'], batch['lab']\n",
    "#     print(f\"Test batch: {images.shape}, {labels.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 'Atelectasis',\n",
       " 'Consolidation': 'Consolidation',\n",
       " 'Infiltration': 'Infiltration',\n",
       " 'Pneumothorax': 'Pneumothorax',\n",
       " 'Edema': 'Edema',\n",
       " 'Emphysema': 'Emphysema',\n",
       " 'Fibrosis': 'Fibrosis',\n",
       " 'Effusion': 'Effusion',\n",
       " 'Pneumonia': 'Pneumonia',\n",
       " 'Pleural_Thickening': 'Pleural_Thickening',\n",
       " 'Cardiomegaly': 'Cardiomegaly',\n",
       " 'Nodule': 'Nodule',\n",
       " 'Mass': 'Mass',\n",
       " 'Hernia': 'Hernia',\n",
       " '': 'Enlarged Cardiomediastinum'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xrv.models.DenseNet(weights=\"nih\").to(device)\n",
    "model.op_threshs = None # Disable calibrated thresholds for the model\n",
    "\n",
    "dict(zip(model.pathologies,xrv.datasets.default_pathologies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Pathologies: ['Fibrosis', 'Pneumothorax', 'Emphysema', 'Pneumonia', 'Infiltration', 'Cardiomegaly', 'Effusion', 'Pleural_Thickening', 'Mass', 'Edema', 'Atelectasis', 'Consolidation', 'Nodule', 'Hernia']\n",
      "Dataset to Model Index Mapping: {6: 6, 3: 3, 5: 5, 8: 8, 2: 2, 10: 10, 7: 7, 9: 9, 12: 12, 4: 4, 0: 0, 1: 1, 11: 11, 13: 13}\n"
     ]
    }
   ],
   "source": [
    "# Align dataset pathologies to model pathologies\n",
    "common_pathologies = list(set(dataset.pathologies) & set(model.pathologies))\n",
    "num_common_pathologies = len(common_pathologies)\n",
    "print(f\"Common Pathologies: {common_pathologies}\")\n",
    "\n",
    "# Map dataset indices to model indices\n",
    "dataset_to_model_indices = {dataset.pathologies.index(p): model.pathologies.index(p) for p in common_pathologies}\n",
    "print(f\"Dataset to Model Index Mapping: {dataset_to_model_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated classifier to output 14 pathologies.\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of output features dynamically\n",
    "dummy_input = torch.zeros(1, 1, 224, 224)  # Batch size 1, single channel, 224x224 input\n",
    "if torch.cuda.is_available():\n",
    "    dummy_input = dummy_input.cuda()\n",
    "\n",
    "# Get the output shape of the feature extractor\n",
    "with torch.no_grad():\n",
    "    num_features = model.features(dummy_input).shape[1]  # The second dimension is the feature size\n",
    "\n",
    "# Update the classifier to match the number of pathologies\n",
    "model.classifier = torch.nn.Linear(num_features, num_common_pathologies).to(device)\n",
    "print(f\"Updated classifier to output {num_common_pathologies} pathologies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated classifier to output 14 pathologies.\n"
     ]
    }
   ],
   "source": [
    "# Update classifier to match the number of common pathologies\n",
    "model.classifier = torch.nn.Linear(num_features, num_common_pathologies).to(device)\n",
    "print(f\"Updated classifier to output {num_common_pathologies} pathologies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.classifier.parameters()) # only train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "model_name = \"first_model\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{model_name}.pth\")\n",
    "\n",
    "# Load checkpoint if available\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, _ = load_checkpoint(checkpoint_path, model, optimizer, scaler)\n",
    "else:\n",
    "    start_epoch = 0  # Start from scratch if no checkpoint is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 0.4565, Validation Loss: 0.2663\n",
      "Checkpoint saved: /mnt/b/Xray/checkpoints/checkpoint_epoch_1.pth\n",
      "Epoch 2 - Training Loss: 0.1998, Validation Loss: 0.1621\n",
      "Checkpoint saved: /mnt/b/Xray/checkpoints/checkpoint_epoch_2.pth\n",
      "Epoch 3 - Training Loss: 0.1416, Validation Loss: 0.1383\n",
      "Checkpoint saved: /mnt/b/Xray/checkpoints/checkpoint_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "train_losses = []  # Store training losses for visualization\n",
    "val_losses = []    # Store validation losses for visualization\n",
    "all_results = []   # Store evaluation metrics\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    # ========================\n",
    "    # Training\n",
    "    # ========================\n",
    "    model.train()\n",
    "    epoch_train_losses = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # Prepare data\n",
    "        batch_tensors = {k: v.to(device, non_blocking=True) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract targets and align for the model\n",
    "        dataset_indices = list(dataset_to_model_indices.keys())\n",
    "        model_indices = list(dataset_to_model_indices.values())\n",
    "        targets = batch_tensors[\"lab\"][:, dataset_indices].float().to(device)\n",
    "        targets_aligned = torch.zeros((targets.size(0), len(model.pathologies)), device=device, dtype=torch.float)\n",
    "        targets_aligned[:, model_indices] = targets\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "            img_input = batch_tensors[\"img\"].to(torch.float16)  # Convert to HalfTensor\n",
    "            outputs = model(img_input)\n",
    "            loss = criterion(outputs[:, model_indices], targets_aligned[:, model_indices])\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Log training loss\n",
    "        epoch_train_losses.append(loss.item())\n",
    "\n",
    "    # Store average training loss for this epoch\n",
    "    avg_train_loss = np.mean(epoch_train_losses)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ========================\n",
    "    # Validation\n",
    "    # ========================\n",
    "    model.eval()\n",
    "    epoch_val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Prepare validation data\n",
    "            batch_tensors = {k: v.to(device, non_blocking=True) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "            # Extract and align targets\n",
    "            targets = batch_tensors[\"lab\"][:, dataset_indices].float().to(device)\n",
    "            targets_aligned = torch.zeros((targets.size(0), len(model.pathologies)), device=device, dtype=torch.float)\n",
    "            targets_aligned[:, model_indices] = targets\n",
    "\n",
    "            # Mixed precision for validation\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "                img_input = batch_tensors[\"img\"]\n",
    "                outputs = model(img_input)\n",
    "                loss = criterion(outputs[:, model_indices], targets_aligned[:, model_indices])\n",
    "\n",
    "            # Log validation loss\n",
    "            epoch_val_losses.append(loss.item())\n",
    "\n",
    "    # Store average validation loss for this epoch\n",
    "    avg_val_loss = np.mean(epoch_val_losses)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\", end=\" \")\n",
    "\n",
    "    # ========================\n",
    "    # Log and Save Checkpoints\n",
    "    # ========================\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch + 1}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "    }, checkpoint_path)\n",
    "    print(\"Checkpoint saved\")\n",
    "\n",
    "# ========================\n",
    "# Loss Curve\n",
    "# ========================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# Final Results\n",
    "# ========================\n",
    "final_results = pd.concat(all_results, keys=range(1, num_epochs + 1))\n",
    "final_results.to_csv(os.path.join(checkpoint_dir, \"evaluation_results.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
