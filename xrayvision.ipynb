{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchxrayvision in ./env/lib/python3.10/site-packages (1.2.4)\n",
      "Requirement already satisfied: matplotlib in ./env/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: ipywidgets in ./env/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-image in ./env/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: seaborn in ./env/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in ./env/lib/python3.10/site-packages (from torchxrayvision) (0.20.1)\n",
      "Requirement already satisfied: imageio in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.36.0)\n",
      "Requirement already satisfied: torch>=1 in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.5.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in ./env/lib/python3.10/site-packages (from torchxrayvision) (11.0.0)\n",
      "Requirement already satisfied: requests>=1 in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4 in ./env/lib/python3.10/site-packages (from torchxrayvision) (4.67.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./env/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./env/lib/python3.10/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./env/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./env/lib/python3.10/site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./env/lib/python3.10/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: networkx>=2.8 in ./env/lib/python3.10/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: exceptiongroup in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: decorator in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: stack-data in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (3.10)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (1.13.1)\n",
      "Requirement already satisfied: triton==3.1.0 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.3.1.170)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (2.21.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1->torchxrayvision) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch>=1->torchxrayvision) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: pure-eval in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchxrayvision matplotlib numpy pandas ipywidgets scikit-learn scikit-image seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TorchXRayVision: A library of chest X-ray datasets and models](https://arxiv.org/pdf/2111.00595)\n",
    "\n",
    "https://github.com/naitik2314/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/projects/Xrays/env/lib/python3.10/site-packages/torchxrayvision/utils.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# PyTorch and data handling\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing\n",
    "import skimage\n",
    "import skimage.transform\n",
    "\n",
    "# Machine learning metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "# TorchXRayVision library\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = max(1, os.cpu_count() - 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_samples = 1000\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"/mnt/b/Xray/images/\"\n",
    "\n",
    "path_dataset = \"/mnt/b/Xray/images/images/\" \n",
    "path_train_val_list = \"/mnt/b/Xray/train_val_list.txt\"\n",
    "path_test_list = \"/mnt/b/Xray/test_list.txt\"\n",
    "\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "path_models = \"/mnt/b/Xray/models/\"\n",
    "checkpoint_dir = \"/mnt/b/Xray/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(link, folder, idx):\n",
    "    \"\"\"Downloads a file from a link to the specified folder.\"\"\"\n",
    "    file_name = f'images_{idx+1:03d}.tar.gz'\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"{file_name} already exists, skipping download.\")\n",
    "        return file_path\n",
    "    try:\n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        urllib.request.urlretrieve(link, file_path)\n",
    "        print(f\"{file_name} downloaded successfully.\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file_path, folder):\n",
    "    \"\"\"Extracts a .tar.gz file to the specified folder.\"\"\"\n",
    "    extracted_flag = file_path.replace('.tar.gz', '_extracted.flag')\n",
    "    if os.path.exists(extracted_flag):\n",
    "        print(f\"{os.path.basename(file_path)} already extracted, skipping.\")\n",
    "        return\n",
    "    try:\n",
    "        print(f\"Extracting {os.path.basename(file_path)}...\")\n",
    "        with tarfile.open(file_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=folder)\n",
    "        with open(extracted_flag, 'w') as f:\n",
    "            f.write('extracted')\n",
    "        print(f\"{os.path.basename(file_path)} extracted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract {os.path.basename(file_path)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_link(idx, link):\n",
    "    \"\"\"Handles downloading and extracting a single link.\"\"\"\n",
    "    file_path = download_file(link, images_dir, idx)\n",
    "    if file_path:\n",
    "        extract_file(file_path, images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    Load the model, optimizer, and scaler states from a checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "        model (torch.nn.Module): The model to load the state into.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "        scaler (torch.cuda.amp.GradScaler): The gradient scaler to load the state into.\n",
    "\n",
    "    Returns:\n",
    "        int: The starting epoch to resume training.\n",
    "        float: The loss at the checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Resuming from epoch {start_epoch}, loss: {loss:.4f}\")\n",
    "    return start_epoch, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_001.tar.gz already exists, skipping download.\n",
      "images_001.tar.gz already extracted, skipping.\n",
      "images_002.tar.gz already exists, skipping download.\n",
      "images_002.tar.gz already extracted, skipping.\n",
      "images_003.tar.gz already exists, skipping download.\n",
      "images_004.tar.gz already exists, skipping download.\n",
      "images_005.tar.gz already exists, skipping download.\n",
      "images_003.tar.gz already extracted, skipping.\n",
      "images_005.tar.gz already extracted, skipping.\n",
      "images_004.tar.gz already extracted, skipping.\n",
      "images_006.tar.gz already exists, skipping download.\n",
      "images_010.tar.gz already exists, skipping download.\n",
      "images_007.tar.gz already exists, skipping download.\n",
      "images_010.tar.gz already extracted, skipping.\n",
      "images_008.tar.gz already exists, skipping download.\n",
      "images_011.tar.gz already exists, skipping download.\n",
      "images_008.tar.gz already extracted, skipping.\n",
      "images_009.tar.gz already exists, skipping download.\n",
      "images_011.tar.gz already extracted, skipping.\n",
      "images_007.tar.gz already extracted, skipping.\n",
      "images_012.tar.gz already exists, skipping download.\n",
      "images_006.tar.gz already extracted, skipping.\n",
      "images_009.tar.gz already extracted, skipping.\n",
      "images_012.tar.gz already extracted, skipping.\n",
      "Download and extraction complete. Please check the extracted files.\n"
     ]
    }
   ],
   "source": [
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(lambda args: process_link(*args), enumerate(links))\n",
    "\n",
    "print(\"Download and extraction complete. Please check the extracted files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    xrv.datasets.XRayCenterCrop(),\n",
    "    xrv.datasets.XRayResizer(224)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lung Lesion doesn't exist. Adding nans instead.\n",
      "Fracture doesn't exist. Adding nans instead.\n",
      "Lung Opacity doesn't exist. Adding nans instead.\n",
      "Enlarged Cardiomediastinum doesn't exist. Adding nans instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = xrv.datasets.NIH_Dataset(\n",
    "    imgpath=path_dataset,\n",
    "    transform=transforms,\n",
    "    views=[\"PA\", \"AP\"],\n",
    "    unique_patients=True, # One image per patient\n",
    ")\n",
    "xrv.datasets.relabel_dataset(xrv.datasets.default_pathologies, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample dataset to the desired number of samples\n",
    "if num_samples < len(dataset):\n",
    "    subset_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "else:\n",
    "    subset_indices = np.arange(len(dataset))  # Use the entire dataset if num_samples exceeds its size\n",
    "\n",
    "# Create a SubsetDataset\n",
    "dataset = xrv.datasets.SubsetDataset(dataset, subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=num_workers*2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([64, 1, 224, 224])\n",
      "Labels batch shape: torch.Size([64, 18])\n"
     ]
    }
   ],
   "source": [
    "# Example: Iterate through a few batches to verify\n",
    "for batch in dataloader:\n",
    "    print(\"Image batch shape:\", batch[\"img\"].shape)\n",
    "    print(\"Labels batch shape:\", batch[\"lab\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = dataset[40]\n",
    "# plt.imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "# dict(zip(dataset.pathologies,sample[\"lab\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 'Atelectasis',\n",
       " 'Consolidation': 'Consolidation',\n",
       " 'Infiltration': 'Infiltration',\n",
       " 'Pneumothorax': 'Pneumothorax',\n",
       " 'Edema': 'Edema',\n",
       " 'Emphysema': 'Emphysema',\n",
       " 'Fibrosis': 'Fibrosis',\n",
       " 'Effusion': 'Effusion',\n",
       " 'Pneumonia': 'Pneumonia',\n",
       " 'Pleural_Thickening': 'Pleural_Thickening',\n",
       " 'Cardiomegaly': 'Cardiomegaly',\n",
       " 'Nodule': 'Nodule',\n",
       " 'Mass': 'Mass',\n",
       " 'Hernia': 'Hernia',\n",
       " '': 'Enlarged Cardiomediastinum'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xrv.models.DenseNet(weights=\"nih\").to(device)\n",
    "model.op_threshs = None # Disable calibrated thresholds for the model\n",
    "\n",
    "dict(zip(model.pathologies,xrv.datasets.default_pathologies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Pathologies: ['Pleural_Thickening', 'Edema', 'Cardiomegaly', 'Infiltration', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Fibrosis', 'Emphysema', 'Nodule', 'Mass', 'Atelectasis', 'Effusion', 'Hernia']\n",
      "Dataset to Model Index Mapping: {9: 9, 4: 4, 10: 10, 2: 2, 8: 8, 3: 3, 1: 1, 6: 6, 5: 5, 11: 11, 12: 12, 0: 0, 7: 7, 13: 13}\n"
     ]
    }
   ],
   "source": [
    "# Align dataset pathologies to model pathologies\n",
    "common_pathologies = list(set(dataset.pathologies) & set(model.pathologies))\n",
    "num_common_pathologies = len(common_pathologies)\n",
    "print(f\"Common Pathologies: {common_pathologies}\")\n",
    "\n",
    "# Map dataset indices to model indices\n",
    "dataset_to_model_indices = {dataset.pathologies.index(p): model.pathologies.index(p) for p in common_pathologies}\n",
    "print(f\"Dataset to Model Index Mapping: {dataset_to_model_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated classifier to output 14 pathologies.\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of output features dynamically\n",
    "dummy_input = torch.zeros(1, 1, 224, 224)  # Batch size 1, single channel, 224x224 input\n",
    "if torch.cuda.is_available():\n",
    "    dummy_input = dummy_input.cuda()\n",
    "\n",
    "# Get the output shape of the feature extractor\n",
    "with torch.no_grad():\n",
    "    num_features = model.features(dummy_input).shape[1]  # The second dimension is the feature size\n",
    "\n",
    "# Update the classifier to match the number of pathologies\n",
    "model.classifier = torch.nn.Linear(num_features, num_common_pathologies).to(device)\n",
    "print(f\"Updated classifier to output {num_common_pathologies} pathologies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated classifier to output 14 pathologies.\n"
     ]
    }
   ],
   "source": [
    "# Update classifier to match the number of common pathologies\n",
    "model.classifier = torch.nn.Linear(num_features, num_common_pathologies).to(device)\n",
    "print(f\"Updated classifier to output {num_common_pathologies} pathologies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.classifier.parameters()) # only train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "model_name = \"first_model\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{model_name}.pth\")\n",
    "\n",
    "# Load checkpoint if available\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, _ = load_checkpoint(checkpoint_path, model, optimizer, scaler)\n",
    "else:\n",
    "    start_epoch = 0  # Start from scratch if no checkpoint is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "losses = []  # Store losses for visualization\n",
    "all_results = []  # Store evaluation metrics\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    epoch_losses = []\n",
    "    model.train()\n",
    "\n",
    "    # ========================\n",
    "    # Train Model\n",
    "    # ========================\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        \n",
    "        # Move data to device\n",
    "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract targets for common pathologies\n",
    "        dataset_indices = list(dataset_to_model_indices.keys())\n",
    "        model_indices = list(dataset_to_model_indices.values())\n",
    "\n",
    "        # Ensure targets have the correct data type\n",
    "        targets = batch[\"lab\"][:, dataset_indices].float()  # Convert to torch.float\n",
    "        targets_aligned = torch.zeros((targets.size(0), len(model.pathologies)), device=device, dtype=torch.float)\n",
    "        targets_aligned[:, model_indices] = targets\n",
    "\n",
    "        # Mixed precision training with autocast\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "            outputs = model(batch[\"img\"])\n",
    "            loss = criterion(outputs[:, model_indices], targets_aligned[:, model_indices])\n",
    "            \n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Log loss\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    # ========================\n",
    "    # Evaluation Metrics\n",
    "    # ========================\n",
    "    model.eval()\n",
    "    outs, labs = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(batch[\"img\"])[:, model_indices].cpu().numpy()\n",
    "            outs.extend(outputs)\n",
    "            labs.extend(batch[\"lab\"][:, dataset_indices].cpu().numpy())\n",
    "\n",
    "    outs = np.array(outs)\n",
    "    labs = np.array(labs)\n",
    "\n",
    "    results = []\n",
    "    for idx, pathology in enumerate(common_pathologies):\n",
    "        result = {\"Pathology\": pathology}\n",
    "        if len(np.unique(labs[:, idx])) > 1:  # Only calculate metrics if labels are not constant\n",
    "            labels = labs[:, idx].astype(bool)\n",
    "            preds = outs[:, idx]\n",
    "            result[\"AUC\"] = roc_auc_score(labels, preds)\n",
    "            result[\"Acc\"] = accuracy_score(labels, preds > 0.5)\n",
    "            result[\"F1\"] = f1_score(labels, preds > 0.5)\n",
    "            result[\"Precision\"] = precision_score(labels, preds > 0.5)\n",
    "            result[\"Recall\"] = recall_score(labels, preds > 0.5)\n",
    "            tn, fp, fn, tp = confusion_matrix(labels, preds > 0.5).ravel()\n",
    "            result[\"Specificity\"] = tn / (tn + fp)\n",
    "            result[\"Balanced Accuracy\"] = balanced_accuracy_score(labels, preds > 0.5)\n",
    "            precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "            result[\"PR AUC\"] = auc(recall, precision)\n",
    "        results.append(result)\n",
    "\n",
    "    # Log results for this epoch\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(f\"Epoch {epoch + 1} Evaluation Results:\")\n",
    "    display(df_results)\n",
    "\n",
    "    all_results.append(df_results)\n",
    "\n",
    "    # Store average loss for the epoch\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ========================\n",
    "    # Visualize\n",
    "    # ========================\n",
    "    \n",
    "    print(f\"Batch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    # Plot sample images\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    for j in range(4):  # Display 4 images\n",
    "        if j < batch[\"img\"].size(0):  # Ensure the batch has enough images\n",
    "            img = batch[\"img\"][j].cpu().numpy().transpose(1, 2, 0)  # Convert to HWC\n",
    "            img = (img - img.min()) / (img.max() - img.min())  # Normalize\n",
    "            axes[j].imshow(img, cmap='gray')\n",
    "            axes[j].axis('off')\n",
    "            axes[j].set_title(f\"Targets: {targets[j].nonzero(as_tuple=True)[0].tolist()}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Store average loss for the epoch\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ========================\n",
    "    # Logging\n",
    "    # ========================\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "# ========================\n",
    "# Loss Curve\n",
    "# ========================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), losses, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# Final Results\n",
    "# ========================\n",
    "final_results = pd.concat(all_results, keys=range(1, num_epochs + 1))\n",
    "final_results.to_csv(os.path.join(checkpoint_dir, \"evaluation_results.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
