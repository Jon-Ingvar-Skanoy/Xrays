{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchxrayvision matplotlib numpy pandas ipywidgets scikit-learn scikit-image seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TorchXRayVision: A library of chest X-ray datasets and models](https://arxiv.org/pdf/2111.00595)\n",
    "\n",
    "https://github.com/naitik2314/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# PyTorch and data handling\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Image processing\n",
    "import skimage\n",
    "import skimage.transform\n",
    "\n",
    "# Machine learning metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "# TorchXRayVision library\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = max(1, os.cpu_count() // 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_samples = 1000\n",
    "num_epochs = 5\n",
    "unique_patients = True\n",
    "pathology_masks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_name = platform.node()  \n",
    "user = os.getenv(\"USER\") or os.getenv(\"USERNAME\") \n",
    "os_name = platform.system()  # Get os\n",
    "print(f\"Machine: {machine_name}, User: {user}, OS: {os_name}\")\n",
    "\n",
    "if machine_name == \"Corsair\" and os_name == \"Linux\" and user == \"jon\":\n",
    "    windows_drive = Path(\"/mnt/b/Xray\")\n",
    "    paths = {\n",
    "        \"dataset\": windows_drive / \"dataset\",\n",
    "        \"tar_images\": windows_drive / \"dataset/images\",\n",
    "        \"images\": windows_drive / \"dataset/images/images\",\n",
    "        \"checkpoints\": windows_drive / \"checkpoints\",\n",
    "        \"papers\": windows_drive / \"papers\",\n",
    "        \"models\": windows_drive / \"models\",\n",
    "    }\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "else:\n",
    "    dataset_dir = Path(\"dataset\")\n",
    "    paths = {\n",
    "        \"dataset\": dataset_dir,\n",
    "        \"tar_images\": dataset_dir / \"images\",\n",
    "        \"images\": dataset_dir / \"images/images\",\n",
    "        \"checkpoints\": dataset_dir / \"checkpoints\",\n",
    "        \"papers\": dataset_dir / \"papers\",\n",
    "        \"models\": dataset_dir / \"models\",\n",
    "    }\n",
    "\n",
    "for key, path in paths.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dir_tar_images = paths['tar_images']\n",
    "\n",
    "path_dataset = paths['dataset']\n",
    "path_images = paths['images']\n",
    "path_csv_list = paths['dataset'] / \"Data_Entry_2017_v2020.csv\"\n",
    "path_train_val_list = paths['dataset'] / \"train_val_list.txt\"\n",
    "path_test_list = paths['dataset'] / \"test_list.txt\"\n",
    "path_models = paths['models']\n",
    "checkpoint_dir = paths['checkpoints']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_file(link, folder, idx):\n",
    "    \"\"\"Downloads a file from a link to the specified folder.\"\"\"\n",
    "    file_name = f'images_{idx+1:03d}.tar.gz'\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        #print(f\"{file_name} already exists, skipping download.\")\n",
    "        return file_path\n",
    "    try:\n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        urllib.request.urlretrieve(link, file_path)\n",
    "        print(f\"{file_name} downloaded successfully.\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_file(file_path, folder):\n",
    "    \"\"\"Extracts a .tar.gz file to the specified folder.\"\"\"\n",
    "    extracted_flag = file_path.replace('.tar.gz', '_extracted.flag')\n",
    "    if os.path.exists(extracted_flag):\n",
    "        #print(f\"{os.path.basename(file_path)} already extracted, skipping.\")\n",
    "        return\n",
    "    try:\n",
    "        print(f\"Extracting {os.path.basename(file_path)}...\")\n",
    "        with tarfile.open(file_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=folder)\n",
    "        with open(extracted_flag, 'w') as f:\n",
    "            f.write('extracted')\n",
    "        print(f\"{os.path.basename(file_path)} extracted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract {os.path.basename(file_path)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_link(idx, link):\n",
    "    \"\"\"Handles downloading and extracting a single link.\"\"\"\n",
    "    file_path = download_file(link, dir_tar_images, idx)\n",
    "    if file_path:\n",
    "        extract_file(file_path, dir_tar_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_file_lists(train_val_path, test_path):\n",
    "    \"\"\"\n",
    "    Load file lists from the provided paths.\n",
    "    \"\"\"\n",
    "    with open(train_val_path, 'r') as f:\n",
    "        train_val_files = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "    with open(test_path, 'r') as f:\n",
    "        test_files = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return train_val_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset_by_file_list(dataset, train_val_files, test_files):\n",
    "    \"\"\"\n",
    "    Split the dataset into train/validation and test sets based on file lists.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The full NIH_Dataset object.\n",
    "        train_val_files: List of filenames for train/validation.\n",
    "        test_files: List of filenames for test.\n",
    "    \n",
    "    Returns:\n",
    "        train_val_dataset, test_dataset: Subsets of the original dataset.\n",
    "    \"\"\"\n",
    "    # Create a mask for matching filenames\n",
    "    train_val_mask = dataset.csv['Image Index'].isin(train_val_files)\n",
    "    test_mask = dataset.csv['Image Index'].isin(test_files)\n",
    "\n",
    "    # Get indices of matched files\n",
    "    train_val_indices = dataset.csv[train_val_mask].index.tolist()\n",
    "    test_indices = dataset.csv[test_mask].index.tolist()\n",
    "\n",
    "    # Create dataset subsets\n",
    "    train_val_dataset = Subset(dataset, train_val_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "    return train_val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer=None, scaler=None):\n",
    "    \"\"\"\n",
    "    Loads a checkpoint and restores the model, optimizer, and scaler states.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file.\n",
    "        model: The model to restore.\n",
    "        optimizer: The optimizer to restore (optional).\n",
    "        scaler: The gradient scaler to restore (optional).\n",
    "\n",
    "    Returns:\n",
    "        start_epoch: The epoch to continue training from.\n",
    "        checkpoint: The full checkpoint dictionary.\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        if scaler:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}\")\n",
    "        return start_epoch, checkpoint\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {checkpoint_path}. Starting from scratch.\")\n",
    "        return 0, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_samples_with_masks(samples, dataset, max_samples=4):\n",
    "    \"\"\"\n",
    "    Plot multiple X-ray images side-by-side along with their semantic and pathology masks (if available).\n",
    "    Only plots samples with available masks, up to `max_samples`.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for sample in samples:\n",
    "        if \"pathology_masks\" in sample and sample[\"pathology_masks\"]:\n",
    "            width = len(sample[\"pathology_masks\"])\n",
    "            fig, axs = plt.subplots(1, max(2, 1 + width), sharey=True, figsize=(3 + 3 * width, 3))\n",
    "            axs[0].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "            axs[0].set_title(f\"Index: {sample['idx']}\")\n",
    "            for i, patho in enumerate(sample[\"pathology_masks\"].keys()):\n",
    "                axs[i + 1].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "                axs[i + 1].imshow(sample[\"pathology_masks\"][patho][0] + 1, alpha=0.5)\n",
    "                axs[i + 1].set_title(dataset.pathologies[patho])\n",
    "            plt.show()\n",
    "            count += 1\n",
    "\n",
    "        elif \"semantic_masks\" in sample and sample[\"semantic_masks\"]:\n",
    "            width = len(sample[\"semantic_masks\"])\n",
    "            fig, axs = plt.subplots(1, max(2, 1 + width), sharey=True, figsize=(3 + 3 * width, 3))\n",
    "            axs[0].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "            axs[0].set_title(f\"Index: {sample['idx']}\")\n",
    "            for i, patho in enumerate(sample[\"semantic_masks\"].keys()):\n",
    "                axs[i + 1].imshow(sample[\"img\"][0], cmap=\"Greys_r\")\n",
    "                axs[i + 1].imshow(sample[\"semantic_masks\"][patho][0] + 1, alpha=0.5)\n",
    "                axs[i + 1].set_title(patho)\n",
    "            plt.show()\n",
    "            count += 1\n",
    "\n",
    "        if count >= max_samples:  # Stop after plotting max_samples\n",
    "            break\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No samples with masks found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    executor.map(lambda args: process_link(*args), enumerate(links))\n",
    "\n",
    "print(\"Download and extraction complete. Please check the extracted files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    xrv.datasets.XRayCenterCrop(),   # Crop the center of the image\n",
    "    xrv.datasets.XRayResizer(224),  # Resize to 224x224\n",
    "    # transforms.ToTensor(),          # Convert to tensor\n",
    "    # transforms.Lambda(lambda x: x.unsqueeze(0) if x.dim() == 2 else x),  # Add channel dimension if missing\n",
    "    # transforms.Lambda(lambda x: (x / 2048.0) * 1024.0)  # Normalize to [-1024, 1024]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xrv.datasets.NIH_Dataset(\n",
    "    imgpath=path_images,\n",
    "    csvpath=f\"{path_dataset}/Data_Entry_2017_v2020.csv\",\n",
    "    transform=transforms,\n",
    "    views=[\"PA\", \"AP\"],\n",
    "    unique_patients=unique_patients, # One image per patient\n",
    "    pathology_masks=pathology_masks, # Load pathology masks\n",
    ")\n",
    "xrv.datasets.relabel_dataset(xrv.datasets.default_pathologies, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_files, test_files = load_file_lists(path_train_val_list, path_test_list)\n",
    "train_val_dataset, test_dataset = split_dataset_by_file_list(dataset, train_val_files, test_files)\n",
    "\n",
    "print(f\"Train/Val Dataset: {len(train_val_dataset)} samples\")\n",
    "print(f\"Test Dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(num_samples))\n",
    "\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Subset(train_val_dataset, train_indices)\n",
    "val_dataset = Subset(train_val_dataset, val_indices)\n",
    "\n",
    "print(f\"Train Dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation Dataset: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=num_workers\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=num_workers\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     images, labels = batch['img'], batch['lab']\n",
    "#     print(f\"Train batch: {images.shape}, {labels.shape}\")\n",
    "#     break\n",
    "\n",
    "# for batch in val_loader:\n",
    "#     images, labels = batch['img'], batch['lab']\n",
    "#     print(f\"Validation batch: {images.shape}, {labels.shape}\")\n",
    "#     break\n",
    "\n",
    "# for batch in test_loader:\n",
    "#     images, labels = batch['img'], batch['lab']\n",
    "#     print(f\"Test batch: {images.shape}, {labels.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xrv.models.DenseNet(weights=\"nih\").to(device)\n",
    "model.op_threshs = None # Disable calibrated thresholds for the model\n",
    "\n",
    "# dict(zip(model.pathologies,xrv.datasets.default_pathologies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align dataset pathologies to model pathologies\n",
    "common_pathologies = list(set(dataset.pathologies) & set(model.pathologies))\n",
    "num_common_pathologies = len(common_pathologies)\n",
    "print(f\"Common Pathologies: {common_pathologies}\")\n",
    "\n",
    "# Map dataset indices to model indices\n",
    "dataset_to_model_indices = {dataset.pathologies.index(p): model.pathologies.index(p) for p in common_pathologies}\n",
    "print(f\"Dataset to Model Index Mapping: {dataset_to_model_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of output features dynamically\n",
    "dummy_input = torch.zeros(1, 1, 224, 224)  # Batch size 1, single channel, 224x224 input\n",
    "if torch.cuda.is_available():\n",
    "    dummy_input = dummy_input.cuda()\n",
    "\n",
    "# Get the output shape of the feature extractor\n",
    "with torch.no_grad():\n",
    "    num_features = model.features(dummy_input).shape[1]  # The second dimension is the feature size\n",
    "\n",
    "# Update the classifier to match the number of pathologies\n",
    "model.classifier = torch.nn.Linear(num_features, num_common_pathologies).to(device)\n",
    "print(f\"Updated classifier to output {num_common_pathologies} pathologies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update classifier to match the number of common pathologies\n",
    "model.classifier = torch.nn.Linear(num_features, num_common_pathologies).to(device)\n",
    "print(f\"Updated classifier to output {num_common_pathologies} pathologies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.classifier.parameters()) # only train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"first_model\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{model_name}.pth\")\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, checkpoint = load_checkpoint(checkpoint_path, model, optimizer, scaler)\n",
    "    if checkpoint:\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        val_losses = checkpoint.get('val_losses', [])\n",
    "        all_results = checkpoint.get('all_results', [])\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    all_results = []\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    # ========================\n",
    "    # Training\n",
    "    # ========================\n",
    "    model.train()\n",
    "    epoch_train_losses = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # Prepare data\n",
    "        batch_tensors = {k: v.to(device, non_blocking=True) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract targets and align for the model\n",
    "        dataset_indices = list(dataset_to_model_indices.keys())\n",
    "        model_indices = list(dataset_to_model_indices.values())\n",
    "        targets = batch_tensors[\"lab\"][:, dataset_indices].float().to(device)\n",
    "        targets_aligned = torch.zeros((targets.size(0), len(model.pathologies)), device=device, dtype=torch.float)\n",
    "        targets_aligned[:, model_indices] = targets\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "            img_input = batch_tensors[\"img\"].to(torch.float16)  # Convert to HalfTensor\n",
    "            outputs = model(img_input)\n",
    "            loss = criterion(outputs[:, model_indices], targets_aligned[:, model_indices])\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Log training loss\n",
    "        epoch_train_losses.append(loss.item())\n",
    "\n",
    "    # Store average training loss for this epoch\n",
    "    avg_train_loss = np.mean(epoch_train_losses)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ========================\n",
    "    # Validation\n",
    "    # ========================\n",
    "    model.eval()\n",
    "    outs, labs = [], []\n",
    "    results = []  # Initialize for each epoch\n",
    "    epoch_val_losses = []  # To store validation losses for the epoch\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Prepare validation data\n",
    "            batch_tensors = {k: v.to(device, non_blocking=True) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "            targets = batch_tensors[\"lab\"][:, dataset_indices].float().to(device)\n",
    "            targets_aligned = torch.zeros((targets.size(0), len(model.pathologies)), device=device, dtype=torch.float)\n",
    "            targets_aligned[:, model_indices] = targets\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "                img_input = batch_tensors[\"img\"]\n",
    "                outputs = model(img_input)\n",
    "                loss = criterion(outputs[:, model_indices], targets_aligned[:, model_indices])\n",
    "\n",
    "            # Log validation loss for the batch\n",
    "            epoch_val_losses.append(loss.item())\n",
    "\n",
    "            # Log outputs and labels\n",
    "            outs.extend(outputs[:, model_indices].detach().cpu().numpy())\n",
    "            labs.extend(targets_aligned[:, model_indices].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        # Calculate Metrics\n",
    "        outs = np.array(outs)\n",
    "        labs = np.array(labs)\n",
    "        for idx, pathology in enumerate(common_pathologies):\n",
    "            result = {\"Pathology\": pathology}\n",
    "            if len(np.unique(labs[:, idx])) > 1:  # Only calculate metrics if labels are not constant\n",
    "                labels = labs[:, idx].astype(bool)\n",
    "                preds = outs[:, idx]\n",
    "                result[\"AUC\"] = roc_auc_score(labels, preds)\n",
    "                result[\"Acc\"] = accuracy_score(labels, preds > 0.5)\n",
    "                result[\"F1\"] = f1_score(labels, preds > 0.5)\n",
    "                result[\"Precision\"] = precision_score(labels, preds > 0.5)\n",
    "                result[\"Recall\"] = recall_score(labels, preds > 0.5)\n",
    "                tn, fp, fn, tp = confusion_matrix(labels, preds > 0.5).ravel()\n",
    "                result[\"Specificity\"] = tn / (tn + fp)\n",
    "                result[\"Balanced Accuracy\"] = balanced_accuracy_score(labels, preds > 0.5)\n",
    "                precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "                result[\"PR AUC\"] = auc(recall, precision)\n",
    "            results.append(result)\n",
    "        \n",
    "        # Append to all_results\n",
    "        if len(results) > 0:\n",
    "            df_results = pd.DataFrame(results)\n",
    "            all_results.append(df_results)\n",
    "            #print(f\"Epoch {epoch + 1} Evaluation Results:\")\n",
    "            #display(df_results)\n",
    "        else:\n",
    "            print(f\"No metrics calculated for epoch {epoch + 1}.\")\n",
    "    \n",
    "    # Store average validation loss for the epoch\n",
    "    avg_val_loss = np.mean(epoch_val_losses)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss: {avg_train_loss:.4f}, Validation Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # ========================\n",
    "    # Log and Save Checkpoints\n",
    "    # ========================\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'train_losses': train_losses,  # Save loss history\n",
    "        'val_losses': val_losses,\n",
    "        'all_results': all_results,   # Save all results\n",
    "    }, checkpoint_path)\n",
    "\n",
    "# ========================\n",
    "# Loss Curve\n",
    "# ========================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# Final Results\n",
    "# ========================\n",
    "if len(all_results) > 0:\n",
    "    final_results = pd.concat(all_results, keys=range(1, len(all_results) + 1))\n",
    "    final_results.to_csv(os.path.join(checkpoint_dir, \"evaluation_results.csv\"), index=False)\n",
    "    print(\"Evaluation results saved.\")\n",
    "\n",
    "    # Summary of metrics (averages across epochs)\n",
    "    metrics_summary = final_results.groupby(\"Pathology\").mean()\n",
    "    print(\"\\nSummary of Metrics Across Epochs:\")\n",
    "    display(metrics_summary)\n",
    "\n",
    "    # Save the summary\n",
    "    metrics_summary.to_csv(os.path.join(checkpoint_dir, \"metrics_summary.csv\"), index=True)\n",
    "else:\n",
    "    print(\"No evaluation results to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
