{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchxrayvision in ./env/lib/python3.10/site-packages (1.2.4)\n",
      "Requirement already satisfied: matplotlib in ./env/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: ipywidgets in ./env/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-image in ./env/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: seaborn in ./env/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in ./env/lib/python3.10/site-packages (from torchxrayvision) (11.0.0)\n",
      "Requirement already satisfied: imageio in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.36.0)\n",
      "Requirement already satisfied: tqdm>=4 in ./env/lib/python3.10/site-packages (from torchxrayvision) (4.67.0)\n",
      "Requirement already satisfied: torch>=1 in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.5.1)\n",
      "Requirement already satisfied: requests>=1 in ./env/lib/python3.10/site-packages (from torchxrayvision) (2.32.3)\n",
      "Requirement already satisfied: torchvision>=0.5 in ./env/lib/python3.10/site-packages (from torchxrayvision) (0.20.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./env/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./env/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./env/lib/python3.10/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: networkx>=2.8 in ./env/lib/python3.10/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./env/lib/python3.10/site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./env/lib/python3.10/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: matplotlib-inline in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: decorator in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: exceptiongroup in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: stack-data in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=1->torchxrayvision) (2.2.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.3.1.170)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (11.6.1.9)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (1.13.1)\n",
      "Requirement already satisfied: triton==3.1.0 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.1.4)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch>=1->torchxrayvision) (3.16.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1->torchxrayvision) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch>=1->torchxrayvision) (3.0.2)\n",
      "Requirement already satisfied: pure-eval in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchxrayvision matplotlib numpy pandas ipywidgets scikit-learn scikit-image seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TorchXRayVision: A library of chest X-ray datasets and models](https://arxiv.org/pdf/2111.00595)\n",
    "\n",
    "https://github.com/naitik2314/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/projects/Xrays/env/lib/python3.10/site-packages/torchxrayvision/utils.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchxrayvision as xrv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage, torch, torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"/mnt/b/Xray/images/\"\n",
    "path_train_val_list = \"/mnt/b/Xray/train_val_list.txt\"\n",
    "path_test_list = \"/mnt/b/Xray/test_list.txt\"\n",
    "\n",
    "os.makedirs(path_dataset, exist_ok=True)\n",
    "\n",
    "path_models = \"/mnt/b/Xray/models/\"\n",
    "checkpoint_dir = \"/mnt/b/Xray/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(link, folder, idx):\n",
    "    \"\"\"Downloads a file from a link to the specified folder.\"\"\"\n",
    "    file_name = f'images_{idx+1:03d}.tar.gz'\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"{file_name} already exists, skipping download.\")\n",
    "        return file_path\n",
    "    try:\n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        urllib.request.urlretrieve(link, file_path)\n",
    "        print(f\"{file_name} downloaded successfully.\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file_path, folder):\n",
    "    \"\"\"Extracts a .tar.gz file to the specified folder.\"\"\"\n",
    "    extracted_flag = file_path.replace('.tar.gz', '_extracted.flag')\n",
    "    if os.path.exists(extracted_flag):\n",
    "        print(f\"{os.path.basename(file_path)} already extracted, skipping.\")\n",
    "        return\n",
    "    try:\n",
    "        print(f\"Extracting {os.path.basename(file_path)}...\")\n",
    "        with tarfile.open(file_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=folder)\n",
    "        with open(extracted_flag, 'w') as f:\n",
    "            f.write('extracted')\n",
    "        print(f\"{os.path.basename(file_path)} extracted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract {os.path.basename(file_path)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_link(idx, link):\n",
    "    \"\"\"Handles downloading and extracting a single link.\"\"\"\n",
    "    file_path = download_file(link, path_dataset, idx)\n",
    "    if file_path:\n",
    "        extract_file(file_path, path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    Load the model, optimizer, and scaler states from a checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "        model (torch.nn.Module): The model to load the state into.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "        scaler (torch.cuda.amp.GradScaler): The gradient scaler to load the state into.\n",
    "\n",
    "    Returns:\n",
    "        int: The starting epoch to resume training.\n",
    "        float: The loss at the checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Resuming from epoch {start_epoch}, loss: {loss:.4f}\")\n",
    "    return start_epoch, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_001.tar.gz already exists, skipping download.\n",
      "images_003.tar.gz already exists, skipping download.\n",
      "images_002.tar.gz already exists, skipping download.\n",
      "images_002.tar.gz already extracted, skipping.\n",
      "images_003.tar.gz already extracted, skipping.\n",
      "images_004.tar.gz already exists, skipping download.\n",
      "images_005.tar.gz already exists, skipping download.\n",
      "images_001.tar.gz already extracted, skipping.\n",
      "Extracting images_005.tar.gz...\n",
      "images_006.tar.gz already exists, skipping download.\n",
      "images_007.tar.gz already exists, skipping download.\n",
      "images_008.tar.gz already exists, skipping download.\n",
      "images_004.tar.gz already extracted, skipping.\n",
      "Extracting images_006.tar.gz...\n",
      "Extracting images_007.tar.gz...\n",
      "Extracting images_008.tar.gz...\n",
      "images_009.tar.gz already exists, skipping download.\n",
      "Extracting images_009.tar.gz...\n",
      "images_005.tar.gz extracted successfully.\n",
      "images_010.tar.gz already exists, skipping download.\n",
      "Extracting images_010.tar.gz...\n",
      "images_006.tar.gz extracted successfully.\n",
      "images_011.tar.gz already exists, skipping download.\n",
      "Extracting images_011.tar.gz...\n",
      "images_008.tar.gz extracted successfully.\n",
      "images_012.tar.gz already exists, skipping download.\n",
      "Extracting images_012.tar.gz...\n",
      "images_007.tar.gz extracted successfully.\n",
      "images_009.tar.gz extracted successfully.\n",
      "images_010.tar.gz extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(lambda args: process_link(*args), enumerate(links))\n",
    "\n",
    "print(\"Download and extraction complete. Please check the extracted files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use XRV transforms to crop and resize the images\n",
    "transforms = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(), xrv.datasets.XRayResizer(224)])\n",
    "\n",
    "dataset = xrv.datasets.NIH_Dataset(imgpath=path_dataset, transform=transforms)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, prefetch_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and erase classifier\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\").to(device)\n",
    "model.op_threshs = None # prevent pre-trained model calibration\n",
    "model.classifier = torch.nn.Linear(1024,1).to(device) # reinitialize classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.classifier.parameters()) # only train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint_epoch_5.pth\")  # Adjust path as needed\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, _ = load_checkpoint(checkpoint_path, model, optimizer, scaler)\n",
    "else:\n",
    "    start_epoch = 0  # Start from scratch if no checkpoint is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 200\n",
    "\n",
    "model_name = \"food11_stamp_kernel3_stride2_lossweigthed_maxnormdyn1_512_64-128-256-512-1024\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "losses = []  # Store losses for visualization\n",
    "for epoch in range(start_epoch, 10):  \n",
    "    epoch_losses = []\n",
    "\n",
    "    # ========================\n",
    "    # Train Model\n",
    "    # ========================\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Move data to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training with autocast\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "            outputs = model(batch[\"img\"])\n",
    "            targets = batch[\"lab\"][:, dataset.pathologies.index(\"Lung Opacity\"), None]\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Log loss\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "        # ========================\n",
    "        # Visualize\n",
    "        # ========================\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n",
    "            # Plot sample images\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "            for j in range(4):  # Display 4 images\n",
    "                if j < batch[\"img\"].size(0):  # Ensure the batch has enough images\n",
    "                    img = batch[\"img\"][j].cpu().numpy().transpose(1, 2, 0)  # Convert to HWC\n",
    "                    img = (img - img.min()) / (img.max() - img.min())  # Normalize\n",
    "                    axes[j].imshow(img, cmap='gray')\n",
    "                    axes[j].axis('off')\n",
    "                    axes[j].set_title(f\"Target: {targets[j].item():.4f}\")\n",
    "            plt.show()\n",
    "\n",
    "    # Store average loss for the epoch\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ========================\n",
    "    # Logging\n",
    "    # ========================\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Loss Curve\n",
    "# ========================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), losses, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
