{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.transforms import v2 as T2\n",
    "from torchvision.models import get_model\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from torch.amp import autocast\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from datetime import datetime\n",
    "import time\n",
    "import jsonlines\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import warnings\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable cuDNN benchmark for optimized performance\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.PngImagePlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_JUPYTER = 'ipykernel' in sys.modules and not IN_COLAB\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "elif IN_JUPYTER:\n",
    "    print(\"Running in Jupyter\")\n",
    "else:\n",
    "    print(\"Not running in Colab or Jupyter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    path_root = '/content/drive/MyDrive/UIA/ikt450/'\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "    # Change directory to your specific folder\n",
    "    os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_dir: /mnt/e/Xray\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "machine_name = platform.node()\n",
    "user = os.getenv(\"USER\") \n",
    "if user == \"jon\":\n",
    "    model_names = ['densenet121', 'densenet161', 'densenet169', 'densenet201']\n",
    "\n",
    "    # if \"dataset\" not in os.listdir():\n",
    "    #     script_dir = \"/mnt/b/Xray\"\n",
    "\n",
    "    script_dir = \"/mnt/e/Xray\"\n",
    "\n",
    "elif user == \"jonal\":\n",
    "    model_names = ['resnet50', 'resnet101', 'resnet152', 'resnext101_32x8d']\n",
    "\n",
    "elif IN_COLAB:\n",
    "    model_names = ['alexnet', 'googlenet', 'inception_v3']\n",
    "\n",
    "else:\n",
    "    model_names = ['mobilenet_v3_large', 'googlenet', 'inception_v3', 'alexnet','convnext_base', 'convnext_large','vit_b_16', 'swin_b','vgg16', 'vgg19'] \n",
    "           \n",
    "#'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7',\n",
    "\n",
    "print(f\"script_dir: {script_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "batch_size = 64\n",
    "num_workers = 2 #max(1, os.cpu_count() // 2)\n",
    "prefetch_factor = 3\n",
    "enable_cache = True\n",
    "rebuild_cache = False\n",
    "num_train_images = None\n",
    "num_test_images = None\n",
    "checkpoint_interval = 10\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_per_model = 5\n",
    "lock_timeout = 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = f\"{script_dir}/dataset/data/train_{image_size}_split\"\n",
    "test_dir = f\"{script_dir}/dataset/data/test_{image_size}_split\"\n",
    "labels_file = f\"{script_dir}/dataset/Data_Entry_2017_v2020.csv\"\n",
    "\n",
    "models_dir = f\"{script_dir}/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "results_dir = f\"{script_dir}/results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "detailed_results_path = f\"{results_dir}/detailed_model_results_{machine_name}_{image_size}_{timestamp}.jsonl\"\n",
    "summary_results_path = f\"{results_dir}/summary_model_results_{machine_name}_{image_size}_{timestamp}.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ChestXray14Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for loading cached tensors and multi-label vectors.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: list, label_mapping: dict, pathologies: list, transform: callable = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list): List of (patient_id, image_path) pairs.\n",
    "            label_mapping (dict): Dictionary mapping image names to label vectors.\n",
    "            pathologies (list): List of pathologies for model alignment.\n",
    "            transform (callable, optional): Transformation function to apply to the images.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.label_mapping = label_mapping\n",
    "        self.pathologies = pathologies\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id, tensor_path, image_name = self.data[idx]\n",
    "\n",
    "        image = decode_image(tensor_path)#, mode=\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = self.label_mapping[image_name]\n",
    "        label_vector = torch.tensor([labels[self.pathologies.index(p)] for p in self.pathologies], dtype=torch.float)\n",
    "        #label_vector = torch.tensor(labels, dtype=torch.float)\n",
    "        return {\"img\": image, \"lab\": label_vector}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterable(iterable: iter, batch_size: int) -> iter:\n",
    "    \"\"\"Yield successive batches from an iterable.\"\"\"\n",
    "    iterator = iter(iterable)\n",
    "    while True:\n",
    "        batch = list(islice(iterator, batch_size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(dataset: list, transform: callable, cache_dir: str, num_workers: int = 1, batch_size: int = 32, enable_cache: bool = True, rebuild_cache: bool = False) -> list:\n",
    "    \"\"\"\n",
    "    Preprocess and save dataset images in batches, with optional caching and multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): List of (patient_id, image_path) pairs.\n",
    "        transform (callable): Transformations to apply to the images.\n",
    "        cache_dir (str): Directory to store cached preprocessed images.\n",
    "        num_workers (int): Number of parallel workers for preprocessing.\n",
    "        batch_size (int): Number of items to process in each batch.\n",
    "        enable_cache (bool): If True, use caching; otherwise, process all files without caching.\n",
    "        rebuild_cache (bool): If True, overwrite existing cache files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (patient_id, cached_image_path or transformed_image) pairs.\n",
    "    \"\"\"\n",
    "    if not enable_cache:\n",
    "        print(\"Caching is disabled. Processing images in memory.\")\n",
    "        return [(patient_id, transform(Image.open(image_path).convert(\"RGB\"))) for patient_id, image_path in dataset]\n",
    "        \n",
    "    if enable_cache:\n",
    "        print(\"\\nBuilding cache...\")\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        if rebuild_cache:\n",
    "            print(f\"Rebuilding cache. Clearing directory: {cache_dir}\")\n",
    "            for file in os.listdir(cache_dir):\n",
    "                file_path = os.path.join(cache_dir, file)\n",
    "                os.remove(file_path)\n",
    "\n",
    "    def process_batch(batch):\n",
    "        results = []\n",
    "        for patient_id, image_path in batch:\n",
    "            cache_path = os.path.join(cache_dir, f\"{os.path.basename(image_path)}.pt\") if enable_cache else None\n",
    "            if not enable_cache or rebuild_cache or (enable_cache and not os.path.exists(cache_path)):\n",
    "                try:\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image = transform(image)\n",
    "                    if enable_cache:\n",
    "                        torch.save(image, cache_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "            results.append((patient_id, cache_path if enable_cache else image))\n",
    "        return results\n",
    "\n",
    "    def worker(input_queue, output_queue):\n",
    "        while True:\n",
    "            batch = input_queue.get()\n",
    "            if batch is None:  # End of queue signal\n",
    "                break\n",
    "            output_queue.put(process_batch(batch))\n",
    "\n",
    "    # Create queues\n",
    "    input_queue = mp.Queue()\n",
    "    output_queue = mp.Queue()\n",
    "    workers = []\n",
    "\n",
    "    # Start worker processes\n",
    "    for i in range(num_workers):\n",
    "        print(f\"Starting worker process {i+1}/{num_workers}\", end=\"\\r\")\n",
    "        process = mp.Process(target=worker, args=(input_queue, output_queue))\n",
    "        process.start()\n",
    "        workers.append(process)\n",
    "    print()\n",
    "\n",
    "    # Divide dataset into batches and add to queue\n",
    "    total_batches = (len(dataset) + batch_size - 1) // batch_size\n",
    "    for i, batch in enumerate(batch_iterable(dataset, batch_size)):\n",
    "        print(f\"Adding batches to queue: {i+1}/{total_batches}\", end=\"\\r\")\n",
    "        input_queue.put(batch)\n",
    "    print()\n",
    "\n",
    "    # Signal workers to terminate\n",
    "    for i in range(num_workers):\n",
    "        input_queue.put(None)\n",
    "\n",
    "    # Collect results\n",
    "    preprocessed_dataset = []\n",
    "    start_time = time.time()\n",
    "    for i in range(total_batches):\n",
    "        batch_start = time.time()\n",
    "        preprocessed_dataset.extend(output_queue.get())\n",
    "        batch_end = time.time()\n",
    "        \n",
    "        # Calculate elapsed time and remaining time\n",
    "        elapsed_time = batch_end - start_time\n",
    "        batches_processed = i + 1\n",
    "        avg_batch_time = elapsed_time / batches_processed\n",
    "        remaining_time = avg_batch_time * (total_batches - batches_processed)\n",
    "        eta = time.strftime('%H:%M:%S', time.gmtime(remaining_time))\n",
    "        \n",
    "        print(f\"Collecting results: {batches_processed}/{total_batches}, ETA: {eta}\", end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "    # Wait for workers to finish\n",
    "    for process in workers:\n",
    "        process.join()\n",
    "\n",
    "    print(f\"Preprocessing complete. Total processed items: {len(preprocessed_dataset)}\")\n",
    "    return preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, directory):\n",
    "    \"\"\"Helper function to process a single file.\"\"\"\n",
    "    if filename.endswith(\".png\"):\n",
    "        patient_id = filename.split(\"_\")[0]\n",
    "        return patient_id, os.path.join(directory, filename)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory: str, max_total_images: int = None, random_selection: bool = False, seed: int = None) -> list:\n",
    "    if random_selection and seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    patient_images = defaultdict(list)\n",
    "\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            patient_id = filename.split(\"_\")[0]\n",
    "            patient_images[patient_id].append(os.path.join(directory, filename))\n",
    "\n",
    "    selected_images = []\n",
    "    for patient_id, images in patient_images.items():\n",
    "        for image in images:\n",
    "        #selected_image = random.choice(images) if random_selection else images[0]\n",
    "\n",
    "            image_name = os.path.basename(image)\n",
    "            selected_images.append((patient_id, image, image_name))\n",
    "            if max_total_images is not None and len(selected_images) >= max_total_images:\n",
    "                break\n",
    "\n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_parallel(directory: str, max_total_images: int = None, random_selection: bool = False, seed: int = None) -> list:\n",
    "    if random_selection and seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # Collect all filenames\n",
    "    filenames = sorted(os.listdir(directory))\n",
    "\n",
    "    # Initialize a defaultdict to group images by patient\n",
    "    patient_images = defaultdict(list)\n",
    "\n",
    "    # Use ThreadPoolExecutor with a progress bar\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(process_file, filename, directory): filename for filename in filenames}\n",
    "\n",
    "        # Use tqdm to track progress\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing files\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                patient_id, image_path = result\n",
    "                patient_images[patient_id].append(image_path)\n",
    "\n",
    "    # Select images\n",
    "    selected_images = []\n",
    "    for patient_id, images in patient_images.items():\n",
    "        for image in images:\n",
    "            image_name = os.path.basename(image)\n",
    "            selected_images.append((patient_id, image, image_name))\n",
    "            if max_total_images is not None and len(selected_images) >= max_total_images:\n",
    "                return selected_images\n",
    "\n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(csv_path: str, conditions: list) -> dict:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = {}\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row['Image Index']\n",
    "        findings = row['Finding Labels'].split('|')\n",
    "        label_vector = [1 if condition in findings else 0 for condition in conditions]\n",
    "        labels[image_path] = label_vector\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_transforms(image_size: int=512, mean: list=[0.485, 0.456, 0.406], std: list=[0.229, 0.224 , 0.225]) -> dict:\n",
    "    \n",
    "    return {\n",
    "        \"train\": T2.Compose([\n",
    "            T2.RandomHorizontalFlip(),\n",
    "            T2.RandomRotation(7),\n",
    "            T2.RandomResizedCrop(\n",
    "                size=(224,224), \n",
    "                scale=(0.08, 1.0),\n",
    "                ratio=(3/4, 4/3),\n",
    "                antialias=True,\n",
    "            ),\n",
    "            T2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            T2.ToDtype(torch.float32, scale=True),\n",
    "            T2.Normalize(mean, std),\n",
    "        ]),\n",
    "        \"val\": T2.Compose([\n",
    "            T2.Resize((image_size, image_size)),\n",
    "            T2.CenterCrop(224),\n",
    "            T2.ToDtype(torch.float32, scale=True),\n",
    "            T2.Normalize(mean, std),\n",
    "        ]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_model(model_name: str, num_classes: int, weights: str = \"DEFAULT\") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Prepare a classification model with custom output classes.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model (must be a valid torchvision model name).\n",
    "        num_classes (int): Number of output classes.\n",
    "        weights (str): Pretrained weights to use. Default is \"DEFAULT\".\n",
    "        \n",
    "    Returns:\n",
    "        model (torch.nn.Module): The prepared model with the custom classification head.\n",
    "    \"\"\"\n",
    "    # Get the model\n",
    "    model = get_model(model_name, weights=weights)\n",
    "\n",
    "    # Replace the classification head based on the model architecture\n",
    "    if hasattr(model, \"fc\"):  # For models like ResNet, RegNet, etc.\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):  # For models like DenseNet, VGG, etc.\n",
    "        if isinstance(model.classifier, nn.Linear):\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "        elif isinstance(model.classifier, nn.Sequential):  # For models like EfficientNet\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "    elif hasattr(model, \"heads\"):  # For Vision Transformers (ViT)\n",
    "        model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} does not have a recognized classification head.\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_loader: DataLoader,\n",
    "                val_loader: DataLoader,\n",
    "                num_epochs: int,\n",
    "                lr: float,\n",
    "                weight_decay: float,\n",
    "                retrain: bool=True,\n",
    "                grad_clip: float=None,\n",
    "                models_dir: str = \"models\",\n",
    "                checkpoint_interval: int = 5) -> nn.Module:\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    if retrain:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                            lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999), eps=1e-08, amsgrad=False)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    epoch_times = [] \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time() \n",
    "        train_loss, val_loss = 0.0, 0.0\n",
    "        os.makedirs(models_dir, exist_ok=True)  \n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch['img'].to(device, non_blocking=True), batch['lab'].to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp): \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images, labels = batch['img'].to(device, non_blocking=True), batch['lab'].to(device, non_blocking=True)\n",
    "                with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        scheduler.step()  # Adjust learning rate\n",
    "\n",
    "        # Calculate epoch duration and remaining time\n",
    "        epoch_duration = time.time() - start_time\n",
    "        epoch_times.append(epoch_duration)\n",
    "        avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
    "        remaining_time = avg_epoch_time * (num_epochs - (epoch + 1))\n",
    "\n",
    "        # Format remaining time as HH:MM:SS\n",
    "        remaining_time_str = time.strftime('%H:%M:%S', time.gmtime(remaining_time))\n",
    "\n",
    "        # Print epoch summary with timing and remaining time\n",
    "        print(f\"    Epoch {epoch+1:03d}/{num_epochs:03d}, \"\n",
    "              f\"Train Loss: {train_losses[-1]:.6f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.6f}, \"\n",
    "              f\"Time: {epoch_duration:.2f} sec, \"\n",
    "              f\"ETA: {remaining_time_str}\", end=\" \")\n",
    "        \n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = f\"{models_dir}/checkpoint_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(\", Checkpoint saved\")\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, val_loader: DataLoader, target_names: list) -> dict:\n",
    "    model.eval()\n",
    "\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, labels = batch['img'].to(device), batch['lab'].to(device)\n",
    "            outputs = torch.sigmoid(model(images))  # Sigmoid for probabilities\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "\n",
    "    # Calculate AUC for each label\n",
    "    auc_scores = []\n",
    "    for i in range(len(target_names)):\n",
    "        if np.sum(actuals[:, i]) == 0 or np.sum(actuals[:, i]) == len(actuals):\n",
    "            print(f\"Skipping AUC calculation for {target_names[i]} (only one class present in labels).\")\n",
    "            auc_scores.append(None)\n",
    "        else:\n",
    "            auc = roc_auc_score(actuals[:, i], predictions[:, i])\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    valid_auc_scores = [auc for auc in auc_scores if auc is not None]\n",
    "    avg_auc = None\n",
    "    if valid_auc_scores:\n",
    "        avg_auc = np.mean(valid_auc_scores)\n",
    "    \n",
    "    return {'predictions': predictions, 'actuals': actuals, 'auc_scores': auc_scores, 'avg_auc': avg_auc}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_combined_radar_chart(results_df: pd.DataFrame) -> None:\n",
    "    \n",
    "    pathologies = results_df[\"Pathology\"].unique()\n",
    "    num_pathologies = len(pathologies)\n",
    "\n",
    "    # Create angle for each pathology\n",
    "    angles = np.linspace(0, 2 * np.pi, num_pathologies, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "\n",
    "    # Prepare figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per pathology and add labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(pathologies, fontsize=10)\n",
    "\n",
    "    # Draw y-labels\n",
    "    ax.set_rscale(\"linear\")\n",
    "    ax.set_rlabel_position(0)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", size=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Colors for each model\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    # Plot test AUCs for each model\n",
    "    for i, model_name in enumerate(results_df[\"Model\"].unique()):\n",
    "        model_results = results_df[results_df[\"Model\"] == model_name]\n",
    "        avg_auc_per_pathology = model_results.groupby(\"Pathology\")[\"Test AUC\"].mean()\n",
    "\n",
    "        test_aucs = avg_auc_per_pathology.tolist()\n",
    "        test_aucs += test_aucs[:1]  # Complete the loop\n",
    "\n",
    "        ax.plot(angles, test_aucs, label=model_name, linestyle='-', color=colors[i % len(colors)])\n",
    "        ax.fill(angles, test_aucs, color=colors[i % len(colors)], alpha=0.1)\n",
    "\n",
    "    # Add legend and title\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1), fontsize=9)\n",
    "    plt.title(\"Combined Radar Chart for Test AUCs of All Models\", size=15, y=1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_radar_chart(model_name: str, results_df: pd.DataFrame) -> None:\n",
    "    pathologies = results_df[\"Pathology\"].unique()\n",
    "    num_pathologies = len(pathologies)\n",
    "\n",
    "    # Prepare data for the specified model\n",
    "    model_results = results_df[results_df[\"Model\"] == model_name]\n",
    "    avg_auc_per_pathology = model_results.groupby(\"Pathology\")[[\"Validation AUC\", \"Test AUC\"]].mean()\n",
    "\n",
    "    # Create angle for each pathology\n",
    "    angles = np.linspace(0, 2 * np.pi, num_pathologies, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "\n",
    "    # Prepare data for radar chart\n",
    "    validation_aucs = avg_auc_per_pathology[\"Validation AUC\"].tolist()\n",
    "    test_aucs = avg_auc_per_pathology[\"Test AUC\"].tolist()\n",
    "    validation_aucs += validation_aucs[:1]  # Complete the loop\n",
    "    test_aucs += test_aucs[:1]\n",
    "\n",
    "    # Start the radar plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per pathology and add labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(pathologies, fontsize=10)\n",
    "\n",
    "    # Draw y-labels\n",
    "    ax.set_rscale(\"linear\")\n",
    "    ax.set_rlabel_position(0)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", size=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Plot data\n",
    "    ax.plot(angles, validation_aucs, label=\"Validation AUC\", linestyle='--', color=\"blue\")\n",
    "    ax.fill(angles, validation_aucs, color=\"blue\", alpha=0.1)\n",
    "\n",
    "    ax.plot(angles, test_aucs, label=\"Test AUC\", linestyle='-', color=\"orange\")\n",
    "    ax.fill(angles, test_aucs, color=\"orange\", alpha=0.1)\n",
    "\n",
    "    # Add legend and title\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title(f\"Radar Chart for Model: {model_name}\", size=15, y=1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pathologies = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Effusion\", \n",
    "                        \"Emphysema\", \"Fibrosis\", \"Hernia\", \"Infiltration\", \"Mass\", \n",
    "                        \"Nodule\", \"Pleural_Thickening\", \"Pneumonia\", \"Pneumothorax\"]\n",
    "\n",
    "label_mapping = load_labels(labels_file, common_pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = get_data_transforms() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = load_dataset(train_dir, random_selection=True, seed=42, max_total_images=num_train_images)\n",
    "#train_val_dataset = load_dataset_parallel(train_dir, random_selection=True, seed=42, max_total_images=num_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate IDs and paths\n",
    "ids = [item[0] for item in train_val_dataset]\n",
    "paths = [item[1] for item in train_val_dataset]\n",
    "names = [item[2] for item in train_val_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, val_idx in splitter.split(paths, groups=ids):\n",
    "    train_data = [(ids[i], paths[i], names[i]) for i in train_idx]\n",
    "    val_data = [(ids[i], paths[i], names[i]) for i in val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset(test_dir, random_selection=False, max_total_images=num_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69625, 16899, 25596)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data leakage detected.\n"
     ]
    }
   ],
   "source": [
    "# check for data leakage\n",
    "ids1 = {item[0] for item in train_data}\n",
    "ids2 = {item[0] for item in val_data}\n",
    "common_ids = ids1.intersection(ids2)\n",
    "\n",
    "if common_ids:\n",
    "    print(\"Data leakage detected! Common IDs:\", common_ids)\n",
    "else:\n",
    "    print(\"No data leakage detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('00000001',\n",
       " '/home/jon/projects/Xrays/dataset/data/train_512/00000001_000.png',\n",
       " '00000001_000.png')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXray14Dataset(train_data, label_mapping, common_pathologies, transform=data_transforms[\"train\"])\n",
    "val_dataset = ChestXray14Dataset(val_data, label_mapping, common_pathologies, transform=data_transforms[\"val\"])\n",
    "test_dataset = ChestXray14Dataset(test_data, label_mapping, common_pathologies, transform=data_transforms[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False, prefetch_factor=prefetch_factor, persistent_workers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00013334120505282098\n",
    "weight_decay = 1.8857522141696178e-06\n",
    "grad_clip =  0.47836246526814713"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize or load existing runs\n",
    "completed_runs = set()\n",
    "\n",
    "if os.path.exists(detailed_results_path):\n",
    "    with jsonlines.open(detailed_results_path) as reader:\n",
    "        for obj in reader:\n",
    "            run_identifier = (obj[\"Model\"], obj[\"Run\"])\n",
    "            completed_runs.add(run_identifier)\n",
    "else:\n",
    "    # Create an empty jsonl file if it doesn't exist\n",
    "    open(detailed_results_path, 'a').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for model: densenet121\n",
      "  Starting run 1 for model densenet121\n",
      "    Preparing model...\n",
      "    Training model...\n"
     ]
    }
   ],
   "source": [
    "# Iterate over models and runs\n",
    "for model_name in model_names:\n",
    "    print(f\"Running experiments for model: {model_name}\")\n",
    "    \n",
    "    for run in range(1, runs_per_model + 1):\n",
    "        run_identifier = (model_name, run)\n",
    "        \n",
    "        if run_identifier in completed_runs:\n",
    "            print(f\"  Skipping already completed run {run} for model {model_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Starting run {run} for model {model_name}\")\n",
    "        \n",
    "        # Prepare and train the model\n",
    "        print(f\"    Preparing model...\")\n",
    "        model = prepare_model(model_name=model_name, num_classes=len(common_pathologies), weights=\"DEFAULT\")\n",
    "        print(f\"    Training model...\")\n",
    "        model = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            num_epochs,\n",
    "            lr,\n",
    "            weight_decay,\n",
    "            retrain=True,\n",
    "            grad_clip=grad_clip,\n",
    "            checkpoint_interval=checkpoint_interval\n",
    "        )\n",
    "        \n",
    "        # Evaluate and test the model\n",
    "        print(f\"    Evaluating model...\")\n",
    "        results_eval = evaluate_model(model, val_loader, target_names=common_pathologies)\n",
    "        print(f\"    Testing model...\")\n",
    "        results_test = evaluate_model(model, test_loader, target_names=common_pathologies)\n",
    "        \n",
    "        # Collect results\n",
    "        print(f\"    Collecting results...\")\n",
    "        run_results = {\n",
    "            \"Model\": model_name,\n",
    "            \"Run\": run,\n",
    "            \"Timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "            \"Results\": []\n",
    "        }\n",
    "        \n",
    "        for i, pathology in enumerate(common_pathologies):\n",
    "            pathology_result = {\n",
    "                \"Pathology\": pathology,\n",
    "                \"Validation AUC\": results_eval['auc_scores'][i] if results_eval['auc_scores'][i] is not None else None,\n",
    "                \"Test AUC\": results_test['auc_scores'][i] if results_test['auc_scores'][i] is not None else None,\n",
    "                \"Validation Predictions\": results_eval['predictions'][:, i].tolist(),\n",
    "                \"Validation Actuals\": results_eval['actuals'][:, i].tolist(),\n",
    "                \"Test Predictions\": results_test['predictions'][:, i].tolist(),\n",
    "                \"Test Actuals\": results_test['actuals'][:, i].tolist()\n",
    "            }\n",
    "            run_results[\"Results\"].append(pathology_result)\n",
    "        \n",
    "        # Save the run results to the jsonl file\n",
    "\n",
    "        with jsonlines.open(detailed_results_path, mode='a') as writer:\n",
    "            writer.write(run_results)\n",
    "        \n",
    "        print(f\"  Results saved for model {model_name}, run {run}\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Generate summary statistics after all runs\n",
    "if os.path.exists(detailed_results_path):\n",
    "    print(\"Generating summary statistics...\")\n",
    "    with jsonlines.open(detailed_results_path) as reader:\n",
    "        all_runs = list(reader)\n",
    "    \n",
    "    # Flatten the results into a DataFrame\n",
    "    summary_data = []\n",
    "    for run in all_runs:\n",
    "        model = run[\"Model\"]\n",
    "        run_num = run[\"Run\"]\n",
    "        for pathology_result in run[\"Results\"]:\n",
    "            summary_entry = {\n",
    "                \"Model\": model,\n",
    "                \"Run\": run_num,\n",
    "                \"Pathology\": pathology_result[\"Pathology\"],\n",
    "                \"Validation AUC\": pathology_result[\"Validation AUC\"],\n",
    "                \"Test AUC\": pathology_result[\"Test AUC\"]\n",
    "            }\n",
    "            summary_data.append(summary_entry)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Convert AUC columns to numeric, coercing errors to NaN\n",
    "    summary_df[\"Validation AUC\"] = pd.to_numeric(summary_df[\"Validation AUC\"], errors=\"coerce\")\n",
    "    summary_df[\"Test AUC\"] = pd.to_numeric(summary_df[\"Test AUC\"], errors=\"coerce\")\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    summary = summary_df.groupby([\"Model\", \"Pathology\"]).agg({\n",
    "        \"Validation AUC\": [\"mean\", \"std\"],\n",
    "        \"Test AUC\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten MultiIndex columns\n",
    "    summary.columns = ['_'.join(col).strip() if col[1] else col[0] for col in summary.columns.values]\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary.to_csv(summary_results_path, index=False)\n",
    "    \n",
    "    print(\"Summary of Results:\")\n",
    "    from IPython.display import display\n",
    "    display(summary)\n",
    "else:\n",
    "    print(\"No detailed results found to generate summary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = f\"{models_dir}/model_{timestamp}.pth\"\n",
    "torch.save(model.state_dict(), model_filename)\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(detailed_results_path)\n",
    "\n",
    "plot_combined_radar_chart(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate radar chart for each model\n",
    "for model_name in results_df[\"Model\"].unique():\n",
    "    plot_radar_chart(model_name, results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_xrays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
