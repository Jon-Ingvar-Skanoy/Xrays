{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.transforms import v2 as T2\n",
    "import torchvision.transforms.v2.functional as F2\n",
    "from torchvision.models import get_model\n",
    "\n",
    "from sklearn.model_selection import  GroupShuffleSplit\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from torch.amp import  autocast\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "import time\n",
    "import jsonlines\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import warnings\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable cuDNN benchmark for optimized performance\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.PngImagePlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_dir: /home/jalarssen/projects/Xrays\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "machine_name = platform.node()\n",
    "user = os.getenv(\"USER\") \n",
    "if user == \"jon\":\n",
    "    model_names = ['densenet121', 'densenet161', 'densenet169', 'densenet201', 'alexnet']\n",
    "\n",
    "    if \"dataset\" not in os.listdir():\n",
    "        script_dir = \"/mnt/b/Xray\"\n",
    "\n",
    "elif user == \"jonal\":\n",
    "    model_names = ['resnet50', 'resnet101', 'resnet152', 'resnext101_32x8d', 'mobilenet_v3_large', 'googlenet', 'inception_v3']\n",
    "\n",
    "else:\n",
    "    model_names = ['densenet121',  'densenet169', 'densenet201', 'resnet50', 'resnet101', 'resnet152'] \n",
    "\n",
    "print(f\"script_dir: {script_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 16#max(1, os.cpu_count() - 2)\n",
    "prefetch_factor = 3\n",
    "pin_memory=True\n",
    "persistent_workers=True\n",
    "enable_cache = True\n",
    "rebuild_cache = False\n",
    "num_train_images = None\n",
    "num_test_images = None\n",
    "checkpoint_interval = 10\n",
    "num_epochs = 20\n",
    "patience = 3\n",
    "runs_per_model = 5\n",
    "\n",
    "lr = 0.00013334120505282098\n",
    "weight_decay = 1.8857522141696178e-06\n",
    "grad_clip =  0.47836246526814713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "labels_file = f\"{script_dir}/dataset/Data_Entry_2017_v2020.csv\"\n",
    "\n",
    "models_dir = f\"{script_dir}/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "results_dir = f\"{script_dir}/results\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ChestXray14Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for loading cached tensors and multi-label vectors.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: list, label_mapping: dict, pathologies: list, transform: callable = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list): List of (patient_id, image_path) pairs.\n",
    "            label_mapping (dict): Dictionary mapping image names to label vectors.\n",
    "            pathologies (list): List of pathologies for model alignment.\n",
    "            transform (callable, optional): Transformation function to apply to the images.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.label_mapping = label_mapping\n",
    "        self.pathologies = pathologies\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id, tensor_path, image_name = self.data[idx]\n",
    "\n",
    "        image = decode_image(tensor_path, mode=\"GRAY\")\n",
    "\n",
    "        # Debug: Inspect original image properties\n",
    "        # original_properties = {\n",
    "        #     \"size\": image.size(),\n",
    "        #     \"dtype\": image.dtype,\n",
    "        #     \"channels\": image.shape[0] if image.ndim == 3 else 1,\n",
    "        # }\n",
    "        # print(f\"Original Image Properties (Idx {idx}): {original_properties} \\n\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Debug: Inspect transformed image properties\n",
    "        # transformed_properties = {\n",
    "        #     \"size\": image.size(),\n",
    "        #     \"dtype\": image.dtype,\n",
    "        #     \"channels\": image.shape[0] if image.ndim == 3 else 1,\n",
    "        # }\n",
    "        # print(f\"Transformed Image Properties (Idx {idx}): {transformed_properties}\\n\")\n",
    "\n",
    "        labels = self.label_mapping[image_name]\n",
    "        label_vector = torch.tensor([labels[self.pathologies.index(p)] for p in self.pathologies], dtype=torch.float)\n",
    "        #label_vector = torch.tensor(labels, dtype=torch.float)\n",
    "        return {\"img\": image, \"lab\": label_vector}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def batch_iterable(iterable: iter, batch_size: int) -> iter:\n",
    "    \"\"\"Yield successive batches from an iterable.\"\"\"\n",
    "    iterator = iter(iterable)\n",
    "    while True:\n",
    "        batch = list(islice(iterator, batch_size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_and_save(dataset: list, transform: callable, cache_dir: str, num_workers: int = 1, batch_size: int = 32, enable_cache: bool = True, rebuild_cache: bool = False) -> list:\n",
    "    \"\"\"\n",
    "    Preprocess and save dataset images in batches, with optional caching and multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): List of (patient_id, image_path) pairs.\n",
    "        transform (callable): Transformations to apply to the images.\n",
    "        cache_dir (str): Directory to store cached preprocessed images.\n",
    "        num_workers (int): Number of parallel workers for preprocessing.\n",
    "        batch_size (int): Number of items to process in each batch.\n",
    "        enable_cache (bool): If True, use caching; otherwise, process all files without caching.\n",
    "        rebuild_cache (bool): If True, overwrite existing cache files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (patient_id, cached_image_path or transformed_image) pairs.\n",
    "    \"\"\"\n",
    "    if not enable_cache:\n",
    "        print(\"Caching is disabled. Processing images in memory.\")\n",
    "        return [(patient_id, transform(Image.open(image_path).convert(\"RGB\"))) for patient_id, image_path in dataset]\n",
    "        \n",
    "    if enable_cache:\n",
    "        print(\"\\nBuilding cache...\")\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        if rebuild_cache:\n",
    "            print(f\"Rebuilding cache. Clearing directory: {cache_dir}\")\n",
    "            for file in os.listdir(cache_dir):\n",
    "                file_path = os.path.join(cache_dir, file)\n",
    "                os.remove(file_path)\n",
    "\n",
    "    def process_batch(batch):\n",
    "        results = []\n",
    "        for patient_id, image_path in batch:\n",
    "            cache_path = os.path.join(cache_dir, f\"{os.path.basename(image_path)}.pt\") if enable_cache else None\n",
    "            if not enable_cache or rebuild_cache or (enable_cache and not os.path.exists(cache_path)):\n",
    "                try:\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image = transform(image)\n",
    "                    if enable_cache:\n",
    "                        torch.save(image, cache_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "            results.append((patient_id, cache_path if enable_cache else image))\n",
    "        return results\n",
    "\n",
    "    def worker(input_queue, output_queue):\n",
    "        while True:\n",
    "            batch = input_queue.get()\n",
    "            if batch is None:  # End of queue signal\n",
    "                break\n",
    "            output_queue.put(process_batch(batch))\n",
    "\n",
    "    # Create queues\n",
    "    input_queue = mp.Queue()\n",
    "    output_queue = mp.Queue()\n",
    "    workers = []\n",
    "\n",
    "    # Start worker processes\n",
    "    for i in range(num_workers):\n",
    "        print(f\"Starting worker process {i+1}/{num_workers}\", end=\"\\r\")\n",
    "        process = mp.Process(target=worker, args=(input_queue, output_queue))\n",
    "        process.start()\n",
    "        workers.append(process)\n",
    "    print()\n",
    "\n",
    "    # Divide dataset into batches and add to queue\n",
    "    total_batches = (len(dataset) + batch_size - 1) // batch_size\n",
    "    for i, batch in enumerate(batch_iterable(dataset, batch_size)):\n",
    "        print(f\"Adding batches to queue: {i+1}/{total_batches}\", end=\"\\r\")\n",
    "        input_queue.put(batch)\n",
    "    print()\n",
    "\n",
    "    # Signal workers to terminate\n",
    "    for i in range(num_workers):\n",
    "        input_queue.put(None)\n",
    "\n",
    "    # Collect results\n",
    "    preprocessed_dataset = []\n",
    "    start_time = time.time()\n",
    "    for i in range(total_batches):\n",
    "        batch_start = time.time()\n",
    "        preprocessed_dataset.extend(output_queue.get())\n",
    "        batch_end = time.time()\n",
    "        \n",
    "        # Calculate elapsed time and remaining time\n",
    "        elapsed_time = batch_end - start_time\n",
    "        batches_processed = i + 1\n",
    "        avg_batch_time = elapsed_time / batches_processed\n",
    "        remaining_time = avg_batch_time * (total_batches - batches_processed)\n",
    "        eta = time.strftime('%H:%M:%S', time.gmtime(remaining_time))\n",
    "        \n",
    "        print(f\"Collecting results: {batches_processed}/{total_batches}, ETA: {eta}\", end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "    # Wait for workers to finish\n",
    "    for process in workers:\n",
    "        process.join()\n",
    "\n",
    "    print(f\"Preprocessing complete. Total processed items: {len(preprocessed_dataset)}\")\n",
    "    return preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(directory: str, max_total_images: int = None, random_selection: bool = False, seed: int = None) -> list:\n",
    "    if random_selection and seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    patient_images = defaultdict(list)\n",
    "\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            patient_id = filename.split(\"_\")[0]\n",
    "            patient_images[patient_id].append(os.path.join(directory, filename))\n",
    "\n",
    "    selected_images = []\n",
    "    for patient_id, images in patient_images.items():\n",
    "        for image in images:\n",
    "        #selected_image = random.choice(images) if random_selection else images[0]\n",
    "\n",
    "            image_name = os.path.basename(image)\n",
    "            selected_images.append((patient_id, image, image_name))\n",
    "            if max_total_images is not None and len(selected_images) >= max_total_images:\n",
    "                break\n",
    "\n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_labels(csv_path: str, conditions: list) -> dict:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = {}\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row['Image Index']\n",
    "        findings = row['Finding Labels'].split('|')\n",
    "        label_vector = [1 if condition in findings else 0 for condition in conditions]\n",
    "        labels[image_path] = label_vector\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_data_transforms(image_size: int=512, mean: list=[0.485, 0.456, 0.406], std: list=[0.229, 0.224 , 0.225]) -> dict:\n",
    "    return {\n",
    "        \"train\": T2.Compose([\n",
    "            T2.RandomHorizontalFlip(),\n",
    "            T2.RandomRotation(7),\n",
    "            T2.RandomResizedCrop(\n",
    "                size=(224,224), \n",
    "                scale=(0.08, 1.0),\n",
    "                ratio=(3/4, 4/3),\n",
    "                antialias=True,\n",
    "            ),\n",
    "            T2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            T2.ToDtype(torch.float32, scale=True),\n",
    "            T2.Normalize(mean, std),\n",
    "        ]),\n",
    "        \"val\": T2.Compose([\n",
    "            T2.Resize((image_size, image_size)),\n",
    "            T2.CenterCrop(224),\n",
    "            T2.ToDtype(torch.float32, scale=True),\n",
    "            T2.Normalize(mean, std),\n",
    "        ]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_model(model_name: str, num_classes: int, weights: str = \"DEFAULT\", input_size: int = 28) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Prepare a classification model with custom output classes and handle smaller input sizes.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model (must be a valid torchvision model name).\n",
    "        num_classes (int): Number of output classes.\n",
    "        weights (str): Pretrained weights to use. Default is \"DEFAULT\".\n",
    "        input_size (int): Input size of the images.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): The prepared model with the custom classification head.\n",
    "    \"\"\"\n",
    "    # Get the model\n",
    "    model = get_model(model_name, weights=weights)\n",
    "\n",
    "    # Adjust the model for smaller input sizes\n",
    "    if input_size < 224:\n",
    "        if model_name.startswith(\"densenet\"):\n",
    "            model.features.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            model.features.pool0 = nn.Identity()\n",
    "            if not hasattr(model.features, \"global_pool\"):\n",
    "                model.features.add_module(\"global_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        elif model_name.startswith(\"vgg\"):\n",
    "            assert \"Not implemented properly\"\n",
    "            # model.features[0] = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "            # model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        elif model_name.startswith(\"resnet\"):\n",
    "            model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            model.maxpool = nn.Identity()\n",
    "        elif model_name.startswith(\"efficientnet\") or model_name.startswith(\"mobilenet\"):\n",
    "            assert \"Not implemented properly\"\n",
    "            # model.features[0][0] = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        elif \"vit\" in model_name or \"vision_transformer\" in model_name:\n",
    "            assert \"Not implemented properly\"\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} does not support smaller input size adjustments.\")\n",
    "\n",
    "    # Replace the classification head\n",
    "    if hasattr(model, \"fc\"):  # For models like ResNet, RegNet, etc.\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):  # For models like DenseNet, VGG, etc.\n",
    "        if isinstance(model.classifier, nn.Linear):\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "        elif isinstance(model.classifier, nn.Sequential):  # For models like EfficientNet\n",
    "            assert \"Not implemented properly\"\n",
    "            #model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "    elif hasattr(model, \"heads\"):  # For Vision Transformers (ViT)\n",
    "        assert \"Not implemented properly\"\n",
    "        #model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} does not have a recognized classification head.\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module,\n",
    "                model_name: str,\n",
    "                train_loader: DataLoader,\n",
    "                val_loader: DataLoader,\n",
    "                num_epochs: int,\n",
    "                lr: float,\n",
    "                weight_decay: float,\n",
    "                patience: int=3,\n",
    "                retrain: bool=True,\n",
    "                grad_clip: float=None,\n",
    "                models_dir: str = \"models\",\n",
    "                checkpoint_interval: int = 5) -> nn.Module:\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    if retrain:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                            lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999), eps=1e-08, amsgrad=False)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    epoch_times = []\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time() \n",
    "        train_loss, val_loss = 0.0, 0.0\n",
    "        os.makedirs(models_dir, exist_ok=True)  \n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch['img'].to(device, non_blocking=True), batch['lab'].to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp): \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images, labels = batch['img'].to(device, non_blocking=True), batch['lab'].to(device, non_blocking=True)\n",
    "                with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        \n",
    "        scheduler.step()  # Adjust learning rate\n",
    "        counter += 1\n",
    "\n",
    "        # Calculate epoch duration and remaining time\n",
    "        epoch_duration = time.time() - start_time\n",
    "        epoch_times.append(epoch_duration)\n",
    "        avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
    "        remaining_time = avg_epoch_time * (num_epochs - (epoch + 1))\n",
    "\n",
    "        # Format remaining time as HH:MM:SS\n",
    "        remaining_time_str = time.strftime('%H:%M:%S', time.gmtime(remaining_time))\n",
    "\n",
    "        # Print epoch summary with timing and remaining time\n",
    "        print(f\"    Epoch {epoch+1:03d}/{num_epochs:03d}, \"\n",
    "              f\"Train Loss: {train_losses[-1]:.6f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.6f}, \"\n",
    "              f\"Time: {epoch_duration:.2f} sec, \"\n",
    "              f\"ETA: {remaining_time_str}\", end=\" \")\n",
    "        \n",
    "        if val_loss/len(val_loader) == min(val_losses):\n",
    "            checkpoint_path = f\"{models_dir}/checkpoint_{model_name}_e_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            counter = 0\n",
    "            print(\", Checkpoint saved\")\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "        if counter == patience:\n",
    "            print(f'Last Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}')  \n",
    "            break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, val_loader: DataLoader, target_names: list) -> dict:\n",
    "    model.eval()\n",
    "\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, labels = batch['img'].to(device), batch['lab'].to(device)\n",
    "            outputs = torch.sigmoid(model(images))  # Sigmoid for probabilities\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "\n",
    "    # Calculate AUC for each label\n",
    "    auc_scores = []\n",
    "    for i in range(len(target_names)):\n",
    "        if np.sum(actuals[:, i]) == 0 or np.sum(actuals[:, i]) == len(actuals):\n",
    "            print(f\"Skipping AUC calculation for {target_names[i]} (only one class present in labels).\")\n",
    "            auc_scores.append(None)\n",
    "        else:\n",
    "            auc = roc_auc_score(actuals[:, i], predictions[:, i])\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    valid_auc_scores = [auc for auc in auc_scores if auc is not None]\n",
    "    avg_auc = None\n",
    "    if valid_auc_scores:\n",
    "        avg_auc = np.mean(valid_auc_scores)\n",
    "    \n",
    "    return {'predictions': predictions, 'actuals': actuals, 'auc_scores': auc_scores, 'avg_auc': avg_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_combined_radar_chart(results_df: pd.DataFrame) -> None:\n",
    "    \n",
    "    pathologies = results_df[\"Pathology\"].unique()\n",
    "    num_pathologies = len(pathologies)\n",
    "\n",
    "    # Create angle for each pathology\n",
    "    angles = np.linspace(0, 2 * np.pi, num_pathologies, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "\n",
    "    # Prepare figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per pathology and add labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(pathologies, fontsize=10)\n",
    "\n",
    "    # Draw y-labels\n",
    "    ax.set_rscale(\"linear\")\n",
    "    ax.set_rlabel_position(0)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", size=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Colors for each model\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    # Plot test AUCs for each model\n",
    "    for i, model_name in enumerate(results_df[\"Model\"].unique()):\n",
    "        model_results = results_df[results_df[\"Model\"] == model_name]\n",
    "        avg_auc_per_pathology = model_results.groupby(\"Pathology\")[\"Test AUC\"].mean()\n",
    "\n",
    "        test_aucs = avg_auc_per_pathology.tolist()\n",
    "        test_aucs += test_aucs[:1]  # Complete the loop\n",
    "\n",
    "        ax.plot(angles, test_aucs, label=model_name, linestyle='-', color=colors[i % len(colors)])\n",
    "        ax.fill(angles, test_aucs, color=colors[i % len(colors)], alpha=0.1)\n",
    "\n",
    "    # Add legend and title\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1), fontsize=9)\n",
    "    plt.title(\"Combined Radar Chart for Test AUCs of All Models\", size=15, y=1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_radar_chart(model_name: str, results_df: pd.DataFrame) -> None:\n",
    "    pathologies = results_df[\"Pathology\"].unique()\n",
    "    num_pathologies = len(pathologies)\n",
    "\n",
    "    # Prepare data for the specified model\n",
    "    model_results = results_df[results_df[\"Model\"] == model_name]\n",
    "    avg_auc_per_pathology = model_results.groupby(\"Pathology\")[[\"Validation AUC\", \"Test AUC\"]].mean()\n",
    "\n",
    "    # Create angle for each pathology\n",
    "    angles = np.linspace(0, 2 * np.pi, num_pathologies, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "\n",
    "    # Prepare data for radar chart\n",
    "    validation_aucs = avg_auc_per_pathology[\"Validation AUC\"].tolist()\n",
    "    test_aucs = avg_auc_per_pathology[\"Test AUC\"].tolist()\n",
    "    validation_aucs += validation_aucs[:1]  # Complete the loop\n",
    "    test_aucs += test_aucs[:1]\n",
    "\n",
    "    # Start the radar plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per pathology and add labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(pathologies, fontsize=10)\n",
    "\n",
    "    # Draw y-labels\n",
    "    ax.set_rscale(\"linear\")\n",
    "    ax.set_rlabel_position(0)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", size=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Plot data\n",
    "    ax.plot(angles, validation_aucs, label=\"Validation AUC\", linestyle='--', color=\"blue\")\n",
    "    ax.fill(angles, validation_aucs, color=\"blue\", alpha=0.1)\n",
    "\n",
    "    ax.plot(angles, test_aucs, label=\"Test AUC\", linestyle='-', color=\"orange\")\n",
    "    ax.fill(angles, test_aucs, color=\"orange\", alpha=0.1)\n",
    "\n",
    "    # Add legend and title\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title(f\"Radar Chart for Model: {model_name}\", size=15, y=1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def inspect_image_properties(image_path):\n",
    "    \"\"\"\n",
    "    Inspect image properties such as size, data type, and number of color channels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            size = img.size  # (width, height)\n",
    "            mode = img.mode  # e.g., \"RGB\", \"L\"\n",
    "            dtype = np.array(img).dtype  # Data type\n",
    "            channels = len(mode) if mode in [\"RGB\", \"RGBA\", \"CMYK\"] else 1\n",
    "            return size, dtype, channels\n",
    "    except Exception as e:\n",
    "        print(f\"Error inspecting image {image_path}: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "common_pathologies = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Effusion\", \n",
    "                        \"Emphysema\", \"Fibrosis\", \"Hernia\", \"Infiltration\", \"Mass\", \n",
    "                        \"Nodule\", \"Pleural_Thickening\", \"Pneumonia\", \"Pneumothorax\"]\n",
    "\n",
    "label_mapping = load_labels(labels_file, common_pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting images in /home/jalarssen/projects/Xrays/dataset/data/train_224\n",
      "Image 1:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/train_224/00000001_000.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 2:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/train_224/00000001_001.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 3:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/train_224/00000001_002.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 4:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/train_224/00000002_000.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 5:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/train_224/00000004_000.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Inspecting images in /home/jalarssen/projects/Xrays/dataset/data/test_224\n",
      "Image 1:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/test_224/00000003_000.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 2:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/test_224/00000003_001.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 3:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/test_224/00000003_002.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 4:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/test_224/00000003_003.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "Image 5:\n",
      "  Path: /home/jalarssen/projects/Xrays/dataset/data/test_224/00000003_004.png\n",
      "  Size: (224, 224)\n",
      "  Data type: uint8\n",
      "  Channels: 3\n",
      "No data leakage detected.\n",
      "Running experiments for model: densenet121\n",
      "  Starting run 1 for model densenet121\n",
      "    Preparing model...\n",
      "    Training model...\n",
      "    Epoch 001/020, Train Loss: 0.178030, Val Loss: 0.140953, Time: 139.15 sec, ETA: 00:44:03 , Checkpoint saved\n",
      "    Epoch 002/020, Train Loss: 0.143228, Val Loss: 0.139378, Time: 119.35 sec, ETA: 00:38:46 , Checkpoint saved\n",
      "    Epoch 003/020, Train Loss: 0.139970, Val Loss: 0.134845, Time: 120.72 sec, ETA: 00:35:48 , Checkpoint saved\n",
      "    Epoch 004/020, Train Loss: 0.137326, Val Loss: 0.134429, Time: 120.34 sec, ETA: 00:33:18 , Checkpoint saved\n",
      "    Epoch 005/020, Train Loss: 0.135792, Val Loss: 0.132733, Time: 120.57 sec, ETA: 00:31:00 , Checkpoint saved\n",
      "    Epoch 006/020, Train Loss: 0.134202, Val Loss: 0.133838, Time: 119.90 sec, ETA: 00:28:46 \n",
      "    Epoch 007/020, Train Loss: 0.132660, Val Loss: 0.131573, Time: 119.82 sec, ETA: 00:26:36 , Checkpoint saved\n",
      "    Epoch 008/020, Train Loss: 0.131371, Val Loss: 0.131064, Time: 121.42 sec, ETA: 00:24:31 , Checkpoint saved\n",
      "    Epoch 009/020, Train Loss: 0.130344, Val Loss: 0.131459, Time: 121.11 sec, ETA: 00:22:27 \n",
      "    Epoch 010/020, Train Loss: 0.129768, Val Loss: 0.131400, Time: 119.64 sec, ETA: 00:20:22 \n",
      "    Epoch 011/020, Train Loss: 0.129419, Val Loss: 0.131317, Time: 121.10 sec, ETA: 00:18:18 \n",
      "Last Epoch 11/20, Train Loss: 0.12941862881074057, Val Loss: 0.1313174045575199\n",
      "    Evaluating model...\n",
      "    Testing model...\n",
      "    Collecting results...\n",
      "  Results saved for model densenet121, run 1\n",
      "  Starting run 2 for model densenet121\n",
      "    Preparing model...\n",
      "    Training model...\n",
      "    Epoch 001/020, Train Loss: 0.176276, Val Loss: 0.141552, Time: 120.09 sec, ETA: 00:38:01 , Checkpoint saved\n",
      "    Epoch 002/020, Train Loss: 0.143088, Val Loss: 0.137275, Time: 119.37 sec, ETA: 00:35:55 , Checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "image_sizes = [28,224,512,1024]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for image_size in image_sizes:\n",
    "    if image_size == 1024:\n",
    "        train_dir = f\"{script_dir}/dataset/data/train\" \n",
    "        test_dir = f\"{script_dir}/dataset/data/test\"\n",
    "    else:\n",
    "        train_dir = f\"{script_dir}/dataset/data/train_{image_size}\" \n",
    "        test_dir = f\"{script_dir}/dataset/data/test_{image_size}\"\n",
    "          \n",
    "    \n",
    "\n",
    "    train_val_dataset = load_dataset(train_dir, random_selection=True, seed=42, max_total_images=num_train_images)\n",
    "\n",
    "    # Separate IDs and paths\n",
    "    ids = [item[0] for item in train_val_dataset]\n",
    "    paths = [item[1] for item in train_val_dataset]\n",
    "    names = [item[2] for item in train_val_dataset]\n",
    "    \n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in splitter.split(paths, groups=ids):\n",
    "        train_data = [(ids[i], paths[i], names[i]) for i in train_idx]\n",
    "        val_data = [(ids[i], paths[i], names[i]) for i in val_idx]\n",
    "    \n",
    "    \n",
    "    test_data = load_dataset(test_dir, random_selection=False, max_total_images=num_test_images)\n",
    "\n",
    "    # Inspect image properties\n",
    "    print(f\"Inspecting images in {train_dir}\")\n",
    "    for idx, (image_id, image_path, image_name) in enumerate(train_val_dataset[:5]):  \n",
    "        size, dtype, channels = inspect_image_properties(image_path)\n",
    "        print(f\"Image {idx + 1}:\")\n",
    "        print(f\"  Path: {image_path}\")\n",
    "        print(f\"  Size: {size}\")\n",
    "        print(f\"  Data type: {dtype}\")\n",
    "        print(f\"  Channels: {channels}\")\n",
    "\n",
    "    print(f\"Inspecting images in {test_dir}\")\n",
    "    for idx, (image_id, image_path, image_name) in enumerate(test_data[:5]):  \n",
    "        size, dtype, channels = inspect_image_properties(image_path)\n",
    "        print(f\"Image {idx + 1}:\")\n",
    "        print(f\"  Path: {image_path}\")\n",
    "        print(f\"  Size: {size}\")\n",
    "        print(f\"  Data type: {dtype}\")\n",
    "        print(f\"  Channels: {channels}\")\n",
    "    \n",
    "    len(train_data), len(val_data), len(test_data)\n",
    "\n",
    "    # check for data leakage\n",
    "    ids1 = {item[0] for item in train_data}\n",
    "    ids2 = {item[0] for item in val_data}\n",
    "    common_ids = ids1.intersection(ids2)\n",
    "    \n",
    "    if common_ids:\n",
    "        print(\"Data leakage detected! Common IDs:\", common_ids)\n",
    "    else:\n",
    "        print(\"No data leakage detected.\")\n",
    "\n",
    "    train_data[0]\n",
    "\n",
    "    #data_transforms = get_data_transforms() \n",
    "    data_transforms = get_data_transforms(image_size)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        ChestXray14Dataset(train_data, label_mapping, common_pathologies, transform=data_transforms[\"train\"]),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        ChestXray14Dataset(val_data, label_mapping, common_pathologies, transform=data_transforms[\"val\"]),\n",
    "        batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        ChestXray14Dataset(test_data, label_mapping, common_pathologies, transform=data_transforms[\"val\"]),\n",
    "        batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Iterate over models and runs\n",
    "    for model_name in model_names:\n",
    "\n",
    "        detailed_results_path = f\"{results_dir}/detailed_model_results_{machine_name}_{image_size}_{model_name}.jsonl\"\n",
    "        summary_results_path = f\"{results_dir}/summary_model_results_{machine_name}_{image_size}_{model_name}.csv\"\n",
    "        # Initialize or load existing runs\n",
    "        completed_runs = set()\n",
    "\n",
    "        if os.path.exists(detailed_results_path):\n",
    "            with jsonlines.open(detailed_results_path) as reader:\n",
    "                for obj in reader:\n",
    "                    run_identifier = (obj[\"Model\"], obj[\"Run\"])\n",
    "                    completed_runs.add(run_identifier)\n",
    "        else:\n",
    "            # Create an empty jsonl file if it doesn't exist\n",
    "            open(detailed_results_path, 'a').close()\n",
    "        print(f\"Running experiments for model: {model_name}\")\n",
    "        \n",
    "        for run in range(1, runs_per_model + 1):\n",
    "            run_identifier = (model_name, run)\n",
    "            \n",
    "            if run_identifier in completed_runs:\n",
    "                print(f\"  Skipping already completed run {run} for model {model_name}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                print(f\"  Starting run {run} for model {model_name}\")\n",
    "                \n",
    "                # Prepare and train the model\n",
    "                print(f\"    Preparing model...\")\n",
    "                model = prepare_model(model_name=model_name,\n",
    "                                      num_classes=len(common_pathologies),\n",
    "                                      weights=\"DEFAULT\",\n",
    "                                      input_size=image_size)\n",
    "                print(f\"    Training model...\")\n",
    "                model = train_model(\n",
    "                    model,\n",
    "                    model_name,\n",
    "                    train_loader,\n",
    "                    val_loader,\n",
    "                    num_epochs,\n",
    "                    lr,\n",
    "                    weight_decay,\n",
    "                    patience=patience,\n",
    "                    retrain=True,\n",
    "                    grad_clip=grad_clip,\n",
    "                    checkpoint_interval=checkpoint_interval\n",
    "                )\n",
    "                \n",
    "                # Evaluate and test the model\n",
    "                print(f\"    Evaluating model...\")\n",
    "                results_eval = evaluate_model(model, val_loader, target_names=common_pathologies)\n",
    "                print(f\"    Testing model...\")\n",
    "                results_test = evaluate_model(model, test_loader, target_names=common_pathologies)\n",
    "                \n",
    "                # Collect results\n",
    "                print(f\"    Collecting results...\")\n",
    "                run_results = {\n",
    "                    \"Model\": model_name,\n",
    "                    \"Run\": run,\n",
    "                    \"Timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "                    \"Results\": []\n",
    "                }\n",
    "                \n",
    "                for i, pathology in enumerate(common_pathologies):\n",
    "                    pathology_result = {\n",
    "                        \"Pathology\": pathology,\n",
    "                        \"Validation AUC\": results_eval['auc_scores'][i] if results_eval['auc_scores'][i] is not None else None,\n",
    "                        \"Test AUC\": results_test['auc_scores'][i] if results_test['auc_scores'][i] is not None else None,\n",
    "                        \"Validation Predictions\": results_eval['predictions'][:, i].tolist(),\n",
    "                        \"Validation Actuals\": results_eval['actuals'][:, i].tolist(),\n",
    "                        \"Test Predictions\": results_test['predictions'][:, i].tolist(),\n",
    "                        \"Test Actuals\": results_test['actuals'][:, i].tolist()\n",
    "                    }\n",
    "                    run_results[\"Results\"].append(pathology_result)\n",
    "                \n",
    "                # Save the run results to the jsonl file\n",
    "                with jsonlines.open(detailed_results_path, mode='a') as writer:\n",
    "                    writer.write(run_results)\n",
    "                \n",
    "                print(f\"  Results saved for model {model_name}, run {run}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error during run {run} for model {model_name}: {e}\")\n",
    "            finally:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Generate summary statistics after all runs\n",
    "        if os.path.exists(detailed_results_path):\n",
    "            print(\"Generating summary statistics...\")\n",
    "            with jsonlines.open(detailed_results_path) as reader:\n",
    "                all_runs = list(reader)\n",
    "            \n",
    "            # Flatten the results into a DataFrame\n",
    "            summary_data = []\n",
    "            for run in all_runs:\n",
    "                model = run[\"Model\"]\n",
    "                run_num = run[\"Run\"]\n",
    "                for pathology_result in run[\"Results\"]:\n",
    "                    summary_entry = {\n",
    "                        \"Model\": model,\n",
    "                        \"Run\": run_num,\n",
    "                        \"Pathology\": pathology_result[\"Pathology\"],\n",
    "                        \"Validation AUC\": pathology_result[\"Validation AUC\"],\n",
    "                        \"Test AUC\": pathology_result[\"Test AUC\"]\n",
    "                    }\n",
    "                    summary_data.append(summary_entry)\n",
    "            \n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            \n",
    "            # Convert AUC columns to numeric, coercing errors to NaN\n",
    "            summary_df[\"Validation AUC\"] = pd.to_numeric(summary_df[\"Validation AUC\"], errors=\"coerce\")\n",
    "            summary_df[\"Test AUC\"] = pd.to_numeric(summary_df[\"Test AUC\"], errors=\"coerce\")\n",
    "            \n",
    "            # Calculate summary statistics\n",
    "            summary = summary_df.groupby([\"Model\", \"Pathology\"]).agg({\n",
    "                \"Validation AUC\": [\"mean\", \"std\"],\n",
    "                \"Test AUC\": [\"mean\", \"std\"]\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Flatten MultiIndex columns\n",
    "            summary.columns = ['_'.join(col).strip() if col[1] else col[0] for col in summary.columns.values]\n",
    "            \n",
    "            # Save summary to CSV\n",
    "            summary.to_csv(summary_results_path, index=False)\n",
    "            \n",
    "            print(\"Summary of Results:\")\n",
    "            \n",
    "            display(summary)\n",
    "        else:\n",
    "            print(\"No detailed results found to generate summary.\")\n",
    "    \n",
    "    \n",
    "    # results_df = pd.read_csv(detailed_results_path)\n",
    "    # plot_combined_radar_chart(results_df)\n",
    "    \n",
    "    # # Generate radar chart for each model\n",
    "    # for model_name in results_df[\"Model\"].unique():\n",
    "    #     plot_radar_chart(model_name, results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_xrays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
